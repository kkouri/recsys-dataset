{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Item relation matrices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (99_080_120, 4)\n",
      "┌──────────┬─────────┬────────────┬────────┐\n",
      "│ session  ┆ aid     ┆ ts         ┆ type   │\n",
      "│ ---      ┆ ---     ┆ ---        ┆ ---    │\n",
      "│ u32      ┆ u32     ┆ u32        ┆ str    │\n",
      "╞══════════╪═════════╪════════════╪════════╡\n",
      "│ 1        ┆ 723931  ┆ 1660544235 ┆ clicks │\n",
      "│ 1        ┆ 1436439 ┆ 1660544269 ┆ clicks │\n",
      "│ 1        ┆ 1693461 ┆ 1660544287 ┆ clicks │\n",
      "│ 1        ┆ 1206554 ┆ 1660544299 ┆ clicks │\n",
      "│ 2        ┆ 1110741 ┆ 1660546139 ┆ clicks │\n",
      "│ …        ┆ …       ┆ …          ┆ …      │\n",
      "│ 13925402 ┆ 1737908 ┆ 1661723987 ┆ clicks │\n",
      "│ 13925403 ┆ 384045  ┆ 1661723976 ┆ clicks │\n",
      "│ 13925403 ┆ 384045  ┆ 1661723986 ┆ clicks │\n",
      "│ 13925404 ┆ 561560  ┆ 1661723983 ┆ clicks │\n",
      "│ 13925404 ┆ 32070   ┆ 1661723994 ┆ clicks │\n",
      "└──────────┴─────────┴────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df_schema = {\"session\": pl.UInt32, \"aid\": pl.UInt32, \"ts\": pl.UInt32, \"type\": pl.Utf8}\n",
    "df = pl.read_csv('../data/generated/train_events_last_half.csv', schema=df_schema)\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Click to click matrix\n",
    "Click to click matrix is defined as the probabilities of other aids being clicked after the previous aid is clicked.\n",
    "Click to click matrix is formed from the sub sessions since there is no point in counting subsequent clicks that are from a user coming back to site after a long time\n",
    "\n",
    "We do multiple variations of the click to click matrix:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next five clicks with time decay. Remove carts and orders from sessions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (111_717_938, 3)\n",
      "┌───────────┬────────────────┬─────────────┐\n",
      "│ click_aid ┆ next_click_aid ┆ probability │\n",
      "│ ---       ┆ ---            ┆ ---         │\n",
      "│ u32       ┆ u32            ┆ f32         │\n",
      "╞═══════════╪════════════════╪═════════════╡\n",
      "│ 0         ┆ 0              ┆ 0.021177    │\n",
      "│ 0         ┆ 13759          ┆ 0.025413    │\n",
      "│ 0         ┆ 31465          ┆ 0.006353    │\n",
      "│ 0         ┆ 39551          ┆ 0.005083    │\n",
      "│ 0         ┆ 53949          ┆ 0.012706    │\n",
      "│ …         ┆ …              ┆ …           │\n",
      "│ 1855602   ┆ 1693232        ┆ 0.050891    │\n",
      "│ 1855602   ┆ 1762441        ┆ 0.010178    │\n",
      "│ 1855602   ┆ 1768521        ┆ 0.010178    │\n",
      "│ 1855602   ┆ 1783511        ┆ 0.076336    │\n",
      "│ 1855602   ┆ 1855602        ┆ 0.063613    │\n",
      "└───────────┴────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "subsequent_clicks_of_sessions = (\n",
    "    df\n",
    "    .filter(pl.col(\"type\") == \"clicks\")\n",
    "    .drop(\"type\")\n",
    "    .sort([\"session\", \"ts\"], descending=[False, False])\n",
    ")\n",
    "\n",
    "subsequent_clicks = pl.DataFrame({\"session\": [], \"aid\": [], \"next_aid\": [], \"weight\": []}, schema={\"session\": pl.UInt32, \"aid\": pl.UInt32, \"next_aid\": pl.UInt32, \"weight\": pl.Float32})\n",
    "\n",
    "n_clicks_ahead = 5\n",
    "for i in range(1, n_clicks_ahead+1):\n",
    "    new_click_pairs = (\n",
    "        # take the original clicks of sessions\n",
    "        subsequent_clicks_of_sessions\n",
    "        .with_columns(\n",
    "            next_session=pl.col(\"session\").shift(-i),\n",
    "            next_aid=pl.col(\"aid\").shift(-i),\n",
    "            weight=pl.lit(1/i).cast(pl.Float32)\n",
    "        )\n",
    "        .filter(pl.col(\"session\") == pl.col(\"next_session\"))\n",
    "        .drop([\"ts\", \"next_session\"])\n",
    "    )\n",
    "    subsequent_clicks = pl.concat([\n",
    "        subsequent_clicks,\n",
    "        new_click_pairs\n",
    "    ])\n",
    "\n",
    "# Sum all the weights for each click-click pair\n",
    "click_to_click_count = (\n",
    "    subsequent_clicks\n",
    "    .group_by([\"aid\", \"next_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each click\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_clicks_total_count = (\n",
    "    click_to_click_count\n",
    "    .group_by(\"aid\")\n",
    "    .agg(pl.col(\"weighted_count\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the probabilities of items being clicked after another item has been clicked\n",
    "click_to_click_matrix = (\n",
    "    click_to_click_count\n",
    "    .join(aid_clicks_total_count, on=\"aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"aid\", \"next_aid\"])\n",
    "    .rename({\"aid\": \"click_aid\", \"next_aid\": \"next_click_aid\"})\n",
    ")\n",
    "\n",
    "print(click_to_click_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "click_to_click_matrix.write_csv(\"./click-to-click-matrix_only-clicks_5-subsequent-clicks-time-decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next five clicks with time decay. Remove carts and orders from sessions. Remove sessions with only 2 events."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (108_596_042, 3)\n",
      "┌───────────┬────────────────┬─────────────┐\n",
      "│ click_aid ┆ next_click_aid ┆ probability │\n",
      "│ ---       ┆ ---            ┆ ---         │\n",
      "│ u32       ┆ u32            ┆ f32         │\n",
      "╞═══════════╪════════════════╪═════════════╡\n",
      "│ 0         ┆ 0              ┆ 0.02173     │\n",
      "│ 0         ┆ 13759          ┆ 0.026076    │\n",
      "│ 0         ┆ 31465          ┆ 0.006519    │\n",
      "│ 0         ┆ 39551          ┆ 0.005215    │\n",
      "│ 0         ┆ 53949          ┆ 0.013038    │\n",
      "│ …         ┆ …              ┆ …           │\n",
      "│ 1855602   ┆ 1693232        ┆ 0.050891    │\n",
      "│ 1855602   ┆ 1762441        ┆ 0.010178    │\n",
      "│ 1855602   ┆ 1768521        ┆ 0.010178    │\n",
      "│ 1855602   ┆ 1783511        ┆ 0.076336    │\n",
      "│ 1855602   ┆ 1855602        ┆ 0.063613    │\n",
      "└───────────┴────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "subsequent_clicks_of_sessions = (\n",
    "    df\n",
    "    .filter(pl.col(\"type\") == \"clicks\")\n",
    "    .drop(\"type\")\n",
    "    .sort([\"session\", \"ts\"], descending=[False, False])\n",
    "    .with_columns(session_event_count=pl.col(\"session\").cum_count().over(\"session\"))\n",
    "    .with_columns(session_event_count=pl.col(\"session_event_count\").max().over(\"session\"))\n",
    "    .filter(pl.col(\"session_event_count\") > 3)\n",
    "    # .filter(pl.col(\"session_event_count\") <= 40)\n",
    "    .drop(\"session_event_count\")\n",
    ")\n",
    "\n",
    "subsequent_clicks = pl.DataFrame({\"session\": [], \"aid\": [], \"next_aid\": [], \"weight\": []}, schema={\"session\": pl.UInt32, \"aid\": pl.UInt32, \"next_aid\": pl.UInt32, \"weight\": pl.Float32})\n",
    "\n",
    "n_clicks_ahead = 5\n",
    "for i in range(1, n_clicks_ahead+1):\n",
    "    new_click_pairs = (\n",
    "        # take the original clicks of sessions\n",
    "        subsequent_clicks_of_sessions\n",
    "        .with_columns(\n",
    "            next_session=pl.col(\"session\").shift(-i),\n",
    "            next_aid=pl.col(\"aid\").shift(-i),\n",
    "            weight=pl.lit(1/i).cast(pl.Float32)\n",
    "        )\n",
    "        .filter(pl.col(\"session\") == pl.col(\"next_session\"))\n",
    "        .drop([\"ts\", \"next_session\"])\n",
    "    )\n",
    "    subsequent_clicks = pl.concat([\n",
    "        subsequent_clicks,\n",
    "        new_click_pairs\n",
    "    ])\n",
    "\n",
    "# Sum all the weights for each click-click pair\n",
    "click_to_click_count = (\n",
    "    subsequent_clicks\n",
    "    .group_by([\"aid\", \"next_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each click\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_clicks_total_count = (\n",
    "    click_to_click_count\n",
    "    .group_by(\"aid\")\n",
    "    .agg(pl.col(\"weighted_count\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the probabilities of items being clicked after another item has been clicked\n",
    "click_to_click_matrix = (\n",
    "    click_to_click_count\n",
    "    .join(aid_clicks_total_count, on=\"aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"aid\", \"next_aid\"])\n",
    "    .rename({\"aid\": \"click_aid\", \"next_aid\": \"next_click_aid\"})\n",
    ")\n",
    "\n",
    "print(click_to_click_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "click_to_click_matrix.write_csv(\"./click-to-click-matrix_only-clicks_5-subsequent-clicks-time-decay_over-3-event-sessions.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Click to cart matrix\n",
    "Click to cart matrix is defined as the probabilities of other aids being added to cart in the same sub session after an aid is clicked.\n",
    "\n",
    "Time decay on carts happening later in the sessions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (38_583_342, 3)\n",
      "┌───────────┬──────────┬─────────────┐\n",
      "│ click_aid ┆ cart_aid ┆ probability │\n",
      "│ ---       ┆ ---      ┆ ---         │\n",
      "│ u32       ┆ u32      ┆ f32         │\n",
      "╞═══════════╪══════════╪═════════════╡\n",
      "│ 0         ┆ 31465    ┆ 0.037618    │\n",
      "│ 0         ┆ 45036    ┆ 0.008681    │\n",
      "│ 0         ┆ 78027    ┆ 0.012539    │\n",
      "│ 0         ┆ 197519   ┆ 0.022571    │\n",
      "│ 0         ┆ 341875   ┆ 0.037618    │\n",
      "│ …         ┆ …        ┆ …           │\n",
      "│ 1855602   ┆ 1030452  ┆ 0.025716    │\n",
      "│ 1855602   ┆ 1192996  ┆ 0.033064    │\n",
      "│ 1855602   ┆ 1376245  ┆ 0.077149    │\n",
      "│ 1855602   ┆ 1768521  ┆ 0.231447    │\n",
      "│ 1855602   ┆ 1783511  ┆ 0.231447    │\n",
      "└───────────┴──────────┴─────────────┘\n",
      "Unique aids: 1390987\n",
      "Total probability: 1390987.0\n"
     ]
    }
   ],
   "source": [
    "sessions = (\n",
    "    df\n",
    "    # Remove subsequent same type events on same aids\n",
    "    .with_columns(\n",
    "        next_session=pl.col(\"session\").shift(-1),\n",
    "        next_aid=pl.col(\"aid\").shift(-1),\n",
    "        next_type=pl.col(\"type\").shift(-1),\n",
    "    )\n",
    "    .filter(pl.when((pl.col(\"session\") == pl.col(\"next_session\")) & (pl.col(\"type\") == pl.col(\"next_type\"))).then((pl.col(\"aid\") != pl.col(\"next_aid\"))).otherwise(True))\n",
    "    .drop([\"next_session\", \"next_aid\", \"next_type\"])\n",
    "    # Calculate the index of each event\n",
    "    # Subsequent carts are considered to be in the same index\n",
    "    .with_columns(cart_id=(pl.col(\"type\") == \"carts\").rle_id())\n",
    "    .with_columns(click_id=(pl.col(\"type\") == \"clicks\").cum_sum())\n",
    "    .with_columns(index=pl.struct(\"session\", \"cart_id\", \"click_id\").rle_id())\n",
    "    .drop([\"cart_id\", \"click_id\"])\n",
    ")\n",
    "\n",
    "# Get clicks and carts of sessions\n",
    "clicks_sessions = (\n",
    "    sessions\n",
    "    .filter(pl.col(\"type\") == \"clicks\")\n",
    "    .rename({\"ts\": \"click_ts\", \"aid\": \"click_aid\", \"index\": \"click_index\"})\n",
    "    .drop(\"type\")\n",
    ")\n",
    "\n",
    "carts_of_sessions = (\n",
    "    sessions\n",
    "    .filter(pl.col(\"type\") == \"carts\")\n",
    "    .rename({\"ts\": \"cart_ts\", \"aid\": \"cart_aid\", \"index\": \"cart_index\"})\n",
    "    .drop(\"type\")\n",
    ")\n",
    "\n",
    "carts_after_clicks_in_sessions = (\n",
    "    carts_of_sessions\n",
    "    # Combine clicks and carts of sessions\n",
    "    .join(clicks_sessions, on=\"session\", how=\"inner\")\n",
    "    # Keep only carts that happened after clicks\n",
    "    .filter(pl.col(\"click_ts\") < pl.col(\"cart_ts\"))\n",
    "    # Weight the click-to-cart relation based in index. Next cart has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"cart_index\")-pl.col(\"click_index\"))).cast(pl.Float32))\n",
    "    .drop([\"click_ts\", \"cart_ts\", \"click_index\", \"cart_index\"])\n",
    ")\n",
    "\n",
    "# Count how many same click to cart events there are\n",
    "click_to_cart_count = (\n",
    "    carts_after_clicks_in_sessions\n",
    "    .group_by([\"click_aid\", \"cart_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    "    .sort(\"weighted_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the clicks for each aid\n",
    "aid_clicks_total_count = (\n",
    "    click_to_cart_count\n",
    "    .group_by(\"click_aid\")\n",
    "    .agg(pl.sum(\"weighted_count\").alias(\"weighted_total_count\"))\n",
    "    .sort(\"weighted_total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being added to cart after another item has been clicked\n",
    "click_to_cart_matrix = (\n",
    "    click_to_cart_count\n",
    "    .join(aid_clicks_total_count, on=\"click_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"click_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "print(click_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", click_to_cart_matrix.select(\"click_aid\").n_unique())\n",
    "print(\"Total probability:\", click_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "click_to_cart_matrix.write_csv(\"./click_to_cart_matrix_time-decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Click to order matrix\n",
    "Click to order matrix is not done since it is not useful. Click to cart matrix works better than any click to order matrix.\n",
    "Possible reasons: 1. Much more carts than orders. 2. Orders are usually done at the end of the session. Carts happen during the session so there is more clear relation between clicks and carts. than clicks and orders."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cart to cart matrix\n",
    "Cart to cart matrix is defined as the probabilities of other aids being added to cart later in the same sub session where an aid is added to cart.\n",
    "\n",
    "time decay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (11_933_532, 3)\n",
      "┌──────────┬───────────────┬─────────────┐\n",
      "│ cart_aid ┆ next_cart_aid ┆ probability │\n",
      "│ ---      ┆ ---           ┆ ---         │\n",
      "│ u32      ┆ u32           ┆ f32         │\n",
      "╞══════════╪═══════════════╪═════════════╡\n",
      "│ 3        ┆ 3             ┆ 0.334078    │\n",
      "│ 3        ┆ 16778         ┆ 0.010841    │\n",
      "│ 3        ┆ 67776         ┆ 0.010841    │\n",
      "│ 3        ┆ 109499        ┆ 0.010841    │\n",
      "│ 3        ┆ 117981        ┆ 0.010841    │\n",
      "│ …        ┆ …             ┆ …           │\n",
      "│ 1855601  ┆ 1158151       ┆ 0.047306    │\n",
      "│ 1855601  ┆ 1326991       ┆ 0.036793    │\n",
      "│ 1855601  ┆ 1566830       ┆ 0.11038     │\n",
      "│ 1855601  ┆ 1700846       ┆ 0.066228    │\n",
      "│ 1855601  ┆ 1786336       ┆ 0.05519     │\n",
      "└──────────┴───────────────┴─────────────┘\n",
      "Unique aids: 725333\n",
      "Total probability: 725333.0\n"
     ]
    }
   ],
   "source": [
    "carts_of_sessions = (\n",
    "    df\n",
    "    .filter(pl.col(\"type\") == \"carts\")\n",
    "    .with_row_index()\n",
    "    .rename({\"ts\": \"cart_ts\", \"aid\": \"cart_aid\", \"index\": \"cart_index\"})\n",
    ")\n",
    "\n",
    "next_carts_of_sessions = (\n",
    "    carts_of_sessions\n",
    "    .rename({\"cart_ts\": \"next_cart_ts\", \"cart_aid\": \"next_cart_aid\", \"cart_index\": \"next_cart_index\"})\n",
    ")\n",
    "\n",
    "# Find subsequent carts in the same session\n",
    "subsequent_carts = (\n",
    "    carts_of_sessions\n",
    "    .join(next_carts_of_sessions, on=\"session\", how=\"inner\")\n",
    "    .filter(pl.col(\"cart_ts\") < pl.col(\"next_cart_ts\"))\n",
    "    .select([\"session\", \"cart_aid\", \"next_cart_aid\", \"cart_index\", \"next_cart_index\"])\n",
    "    # Weight the cart-to-cart relation based in index. Next cart has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"next_cart_index\")-pl.col(\"cart_index\"))).cast(pl.Float32))\n",
    "    .drop([\"cart_index\", \"next_cart_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each cart-cart pair\n",
    "cart_to_cart_count = (\n",
    "    subsequent_carts\n",
    "    .group_by([\"cart_aid\", \"next_cart_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each cart\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_carts_total_count = (\n",
    "    subsequent_carts\n",
    "    .group_by(\"cart_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being added to cart after another item has been clicked\n",
    "cart_to_cart_matrix = (\n",
    "    cart_to_cart_count\n",
    "    .join(aid_carts_total_count, on=\"cart_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"cart_aid\", \"next_cart_aid\"])\n",
    ")\n",
    "\n",
    "print(cart_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", cart_to_cart_matrix.select(\"cart_aid\").n_unique())\n",
    "print(\"Total probability:\", cart_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "cart_to_cart_matrix.write_csv(\"./cart_to_cart_matrix_time-decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cart to order matrix\n",
    "Cart to order matrix is defined as the probabilities of other aids being ordered later in the same sub session where an aid is added to cart."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (6_051_171, 3)\n",
      "┌──────────┬───────────┬─────────────┐\n",
      "│ cart_aid ┆ order_aid ┆ probability │\n",
      "│ ---      ┆ ---       ┆ ---         │\n",
      "│ u32      ┆ u32       ┆ f32         │\n",
      "╞══════════╪═══════════╪═════════════╡\n",
      "│ 3        ┆ 3         ┆ 0.538462    │\n",
      "│ 3        ┆ 22107     ┆ 0.019231    │\n",
      "│ 3        ┆ 67776     ┆ 0.019231    │\n",
      "│ 3        ┆ 138431    ┆ 0.019231    │\n",
      "│ 3        ┆ 164205    ┆ 0.019231    │\n",
      "│ …        ┆ …         ┆ …           │\n",
      "│ 1855601  ┆ 1360116   ┆ 0.1         │\n",
      "│ 1855601  ┆ 1486834   ┆ 0.1         │\n",
      "│ 1855601  ┆ 1566830   ┆ 0.1         │\n",
      "│ 1855601  ┆ 1700846   ┆ 0.1         │\n",
      "│ 1855601  ┆ 1786336   ┆ 0.1         │\n",
      "└──────────┴───────────┴─────────────┘\n",
      "Unique aids: 521691\n",
      "Total probability: 521690.96875\n"
     ]
    }
   ],
   "source": [
    "# orders and carts preceding orders are grouped together\n",
    "grouped_orders_and_carts = (\n",
    "    df\n",
    "    .sort([\"session\", \"ts\"])\n",
    "    .filter(pl.col(\"type\") != \"clicks\")\n",
    "    # Filter out sessions with no orders\n",
    "    .group_by(\"session\")\n",
    "    .agg(pl.all(), pl.col(\"type\").filter(pl.col(\"type\") == \"orders\").n_unique().alias(\"has_orders\"))\n",
    "    .filter(pl.col(\"has_orders\") == 1)\n",
    "    .drop(\"has_orders\")\n",
    "    .explode([\"aid\", \"ts\", \"type\"])\n",
    "    # Group orders and clicks\n",
    "    .with_columns(order_timestamp_mask=pl.when(pl.col(\"type\") == \"orders\").then(pl.col(\"ts\")).otherwise(0).cast(pl.UInt32))\n",
    "    .with_columns(group=pl.struct(\"session\", \"order_timestamp_mask\").rle_id().cast(pl.UInt32))\n",
    "    .with_columns(group=pl.when(pl.col(\"type\") == \"carts\").then(pl.col(\"group\") + 1).otherwise(pl.col(\"group\")))\n",
    "    .drop([\"order_timestamp_mask\", \"session\", \"ts\"])\n",
    "    # Remove duplicate clicks and orders of groups\n",
    "    .unique(maintain_order=True)\n",
    ")\n",
    "\n",
    "cart_to_order_count = (\n",
    "    grouped_orders_and_carts\n",
    "    .filter(pl.col(\"type\") == \"carts\")\n",
    "    .drop(\"type\")\n",
    "    .rename({\"aid\": \"cart_aid\"})\n",
    "    .join(\n",
    "        (\n",
    "            grouped_orders_and_carts\n",
    "            .filter(pl.col(\"type\") == \"orders\")\n",
    "            .drop(\"type\")\n",
    "            .rename({\"aid\": \"order_aid\"})\n",
    "        ), on=\"group\", how=\"inner\")\n",
    "    .group_by([\"cart_aid\", \"order_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    ")\n",
    "\n",
    "# Sum all the carts for each aid\n",
    "aid_carts_total_count = (\n",
    "    cart_to_order_count\n",
    "    .group_by(\"cart_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being ordered after another item has been added to cart\n",
    "cart_to_order_matrix = (\n",
    "    cart_to_order_count\n",
    "    .join(aid_carts_total_count, on=\"cart_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"cart_aid\", \"order_aid\"])\n",
    ")\n",
    "\n",
    "print(cart_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", cart_to_order_matrix.select(\"cart_aid\").n_unique())\n",
    "print(\"Total probability:\", cart_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "cart_to_order_matrix.write_csv(\"./cart_to_order_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cart to order with time decay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = (\n",
    "    get_sub_sessions(with_next_event=False)\n",
    "    # Filter out clicks\n",
    "    .filter(pl.col(\"type\") != \"clicks\")\n",
    "    .with_columns(index=(pl.col(\"sub_session\") + (pl.col(\"type\") == \"orders\").cum_sum()))\n",
    ")\n",
    "\n",
    "# Get clicks and orders of sessions\n",
    "carts_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"carts\")\n",
    "    .rename({\"ts\": \"cart_ts\", \"aid\": \"cart_aid\", \"index\": \"cart_index\"})\n",
    ")\n",
    "\n",
    "orders_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .rename({\"ts\": \"order_ts\", \"aid\": \"order_aid\", \"index\": \"order_index\"})\n",
    ")\n",
    "\n",
    "orders_after_carts_in_sub_sessions = (\n",
    "    orders_of_sub_sessions\n",
    "    # Combine carts and orders of sessions\n",
    "    .join(carts_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only orders that happened after carts\n",
    "    .filter(pl.col(\"cart_ts\") < pl.col(\"order_ts\"))\n",
    "    .select([\"sub_session\", \"cart_aid\", \"order_aid\", \"cart_index\", \"order_index\"])\n",
    "    # Weight the cart-to-order relation based in index. Next order has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"order_index\")-pl.col(\"cart_index\"))).cast(pl.Float32))\n",
    "    .drop([\"cart_index\", \"order_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each cart-order pair\n",
    "cart_to_order_count = (\n",
    "    orders_after_carts_in_sub_sessions\n",
    "    .group_by([\"cart_aid\", \"order_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each cart\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_carts_total_count = (\n",
    "    orders_after_carts_in_sub_sessions\n",
    "    .group_by(\"cart_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being added to order after another item has been clicked\n",
    "cart_to_order_matrix = (\n",
    "    cart_to_order_count\n",
    "    .join(aid_carts_total_count, on=\"cart_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"cart_aid\", \"order_aid\"])\n",
    ")\n",
    "\n",
    "print(cart_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", cart_to_order_matrix.select(\"cart_aid\").n_unique())\n",
    "print(\"Total probability:\", cart_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "cart_to_order_matrix.write_csv(\"./cart_to_order_matrix_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cart to order from whole sessions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (28_135_990, 3)\n",
      "┌─────────┬──────────┬─────────────┐\n",
      "│ aid     ┆ next_aid ┆ probability │\n",
      "│ ---     ┆ ---      ┆ ---         │\n",
      "│ u32     ┆ u32      ┆ f32         │\n",
      "╞═════════╪══════════╪═════════════╡\n",
      "│ 3       ┆ 3        ┆ 0.366832    │\n",
      "│ 3       ┆ 22107    ┆ 0.00957     │\n",
      "│ 3       ┆ 61428    ┆ 0.00957     │\n",
      "│ 3       ┆ 67776    ┆ 0.00957     │\n",
      "│ 3       ┆ 68426    ┆ 0.00319     │\n",
      "│ …       ┆ …        ┆ …           │\n",
      "│ 1855601 ┆ 1486834  ┆ 0.062241    │\n",
      "│ 1855601 ┆ 1566830  ┆ 0.062241    │\n",
      "│ 1855601 ┆ 1700846  ┆ 0.082988    │\n",
      "│ 1855601 ┆ 1712873  ┆ 0.062241    │\n",
      "│ 1855601 ┆ 1786336  ┆ 0.062241    │\n",
      "└─────────┴──────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "carts_and_orders_df = (\n",
    "    df\n",
    "    .explode(\"events\")\n",
    "    .unnest(\"events\")\n",
    "    .filter(pl.col(\"type\") != \"clicks\")\n",
    "    .sort([\"session\", \"ts\"], descending=[False, False])\n",
    "    .drop(\"ts\")\n",
    "    # Make groups based on types and then make sure that session boundaries are not crossed\n",
    "    .with_columns(group=(pl.col(\"type\") == \"orders\").rle_id().cast(pl.UInt32))\n",
    "    .with_columns(group=pl.struct(\"session\", \"group\").rle_id())\n",
    "    # Remove multiple carts and orders in the same group\n",
    "    .unique()\n",
    "    .lazy()\n",
    ")\n",
    "\n",
    "cart_to_order = (\n",
    "     carts_and_orders_df\n",
    "    .join(carts_and_orders_df.rename({\"group\": \"next_group\", \"aid\": \"next_aid\", \"type\": \"next_type\" }), on=\"session\", how=\"inner\")\n",
    "    .filter(pl.col(\"group\") < pl.col(\"next_group\"))\n",
    "    .filter((pl.col(\"type\") == \"carts\") & (pl.col(\"next_type\") == \"orders\"))\n",
    "    .drop([\"type\", \"next_type\"])\n",
    "    # time decay\n",
    "    .with_columns(weight = (1 / (pl.col(\"next_group\") - pl.col(\"group\"))).cast(pl.Float32))\n",
    "    .drop([\"group\", \"next_group\"])\n",
    ")\n",
    "\n",
    "cart_to_order_count = (\n",
    "    cart_to_order\n",
    "    .group_by([\"aid\", \"next_aid\"])\n",
    "    # time decay\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    "    # no time decay\n",
    "    # .agg(pl.len().alias(\"count\"))\n",
    "    # .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "cart_aid_total_count = (\n",
    "    cart_to_order_count\n",
    "    .group_by(\"aid\")\n",
    "    # time decay\n",
    "    .agg(pl.col(\"weighted_count\").sum().alias(\"weighted_total_count\"))\n",
    "    # no time decay\n",
    "    # .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    # .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "cart_to_order_matrix_df = (\n",
    "    cart_to_order_count\n",
    "    .join(cart_aid_total_count, on=\"aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"aid\", \"next_aid\"])\n",
    "    .collect(streaming=True)\n",
    ")\n",
    "\n",
    "print(cart_to_order_matrix_df)\n",
    "\n",
    "# save to csv\n",
    "cart_to_order_matrix_df.write_csv(\"./cart_to_order_matrix_whole_sessions_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Order to click matrix\n",
    "Order to click matrix is defined as the probabilities of other aids being clicked immediately after an aid is ordered."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get orders and clicks of sessions\n",
    "orders_of_sub_sessions = get_orders_of_sub_session(sub_sessions)\n",
    "\n",
    "clicks_of_sub_sessions = get_clicks_of_sub_session(sub_sessions)\n",
    "\n",
    "clicks_after_orders_in_sub_sessions = (\n",
    "    clicks_of_sub_sessions\n",
    "    # Combine orders and clicks of sessions\n",
    "    .join(orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only clicks that happened after orders\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"click_ts\"))\n",
    "    .select([\"sub_session\", \"order_aid\", \"click_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same order to click events there are\n",
    "order_to_click_count = (\n",
    "    clicks_after_orders_in_sub_sessions\n",
    "    .group_by([\"order_aid\", \"click_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the orders for each aid\n",
    "aid_orders_total_count = (\n",
    "    order_to_click_count\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being clicked immediately after another item has been ordered\n",
    "order_to_click_matrix = (\n",
    "    order_to_click_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"order_aid\", \"click_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_click_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_click_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_click_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_click_matrix.write_csv(\"./order_to_click_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Order to cart matrix\n",
    "Order to cart matrix is defined as the probabilities of other aids being added to cart later in the same sub session where an aid is ordered.s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get orders and carts of sessions\n",
    "orders_of_sub_sessions = get_orders_of_sub_session(sub_sessions)\n",
    "\n",
    "carts_of_sub_sessions = get_carts_of_sub_session(sub_sessions)\n",
    "\n",
    "carts_after_orders_in_sub_sessions = (\n",
    "    carts_of_sub_sessions\n",
    "    # Combine orders and carts of sessions\n",
    "    .join(orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only carts that happened after orders\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"cart_ts\"))\n",
    "    .select([\"sub_session\", \"order_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same order to cart events there are\n",
    "order_to_cart_count = (\n",
    "    carts_after_orders_in_sub_sessions\n",
    "    .group_by([\"order_aid\", \"cart_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the orders for each aid\n",
    "aid_orders_total_count = (\n",
    "    order_to_cart_count\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being added to cart after another item has been ordered\n",
    "order_to_cart_matrix = (\n",
    "    order_to_cart_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"order_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_cart_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_cart_matrix.write_csv(\"./order_to_cart_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Order to cart with time decay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = (\n",
    "    get_sub_sessions(with_next_event=False)\n",
    "    # Filter out clicks\n",
    "    .filter(pl.col(\"type\") != \"clicks\")\n",
    "    .with_columns(index=(pl.col(\"sub_session\") + (pl.col(\"type\") == \"cart\").cum_sum()))\n",
    ")\n",
    "\n",
    "# Get clicks and orders of sessions\n",
    "orders_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .rename({\"ts\": \"order_ts\", \"aid\": \"order_aid\", \"index\": \"order_index\"})\n",
    ")\n",
    "\n",
    "carts_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"carts\")\n",
    "    .rename({\"ts\": \"cart_ts\", \"aid\": \"cart_aid\", \"index\": \"cart_index\"})\n",
    ")\n",
    "\n",
    "carts_after_orders_in_sub_sessions = (\n",
    "    carts_of_sub_sessions\n",
    "    # Combine carts and orders of sessions\n",
    "    .join(orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only orders that happened after carts\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"cart_ts\"))\n",
    "    .select([\"sub_session\", \"cart_aid\", \"order_aid\", \"cart_index\", \"order_index\"])\n",
    "    # Weight the cart-to-order relation based in index. Next order has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"cart_index\")-pl.col(\"order_index\"))).cast(pl.Float32))\n",
    "    .drop([\"cart_index\", \"order_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each order-cart pair\n",
    "order_to_cart_count = (\n",
    "    orders_after_carts_in_sub_sessions\n",
    "    .group_by([\"order_aid\", \"cart_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each cart\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_orders_total_count = (\n",
    "    orders_after_carts_in_sub_sessions\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being added to cart after another item has been ordered\n",
    "order_to_cart_matrix = (\n",
    "    order_to_cart_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"order_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_cart_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_cart_matrix.write_csv(\"./order_to_cart_matrix_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Order to order matrix\n",
    "Order to order matrix is defined as the probabilities of other aids being ordered later in the same sub session where an aid is ordered.s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get orders of sessions\n",
    "orders_of_sub_sessions = get_orders_of_sub_session(sub_sessions)\n",
    "\n",
    "next_orders_of_sub_sessions = (\n",
    "    orders_of_sub_sessions\n",
    "    .rename({\"order_ts\": \"next_order_ts\", \"order_aid\": \"next_order_aid\"})\n",
    ")\n",
    "\n",
    "# Find subsequent orders in the same session\n",
    "subsequent_orders = (\n",
    "    orders_of_sub_sessions\n",
    "    .join(next_orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"next_order_ts\"))\n",
    "    .select([\"sub_session\", \"order_aid\", \"next_order_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same order to order events there are\n",
    "subsequent_orders_count = (\n",
    "    subsequent_orders\n",
    "    .group_by([\"order_aid\", \"next_order_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the orders for each aid\n",
    "aid_orders_total_count = (\n",
    "    subsequent_orders_count\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being ordered after another item has been ordered\n",
    "order_to_order_matrix = (\n",
    "    subsequent_orders_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"order_aid\", \"next_order_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_order_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_order_matrix.write_csv(\"./order_to_order_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Order to order with time decay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "orders_of_sub_sessions = (\n",
    "    get_sub_sessions(with_next_event=False)\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .with_row_index()\n",
    "    .rename({\"ts\": \"order_ts\", \"aid\": \"order_aid\", \"index\": \"order_index\"})\n",
    ")\n",
    "\n",
    "next_orders_of_sub_sessions = (\n",
    "    orders_of_sub_sessions\n",
    "    .rename({\"order_ts\": \"next_order_ts\", \"order_aid\": \"next_order_aid\", \"order_index\": \"next_order_index\"})\n",
    ")\n",
    "\n",
    "# Find subsequent orders in the same session\n",
    "subsequent_orders = (\n",
    "    orders_of_sub_sessions\n",
    "    .join(next_orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"next_order_ts\"))\n",
    "    .select([\"sub_session\", \"order_aid\", \"next_order_aid\", \"order_index\", \"next_order_index\"])\n",
    "    # Weight the order-to-order relation based in index. Next order has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"next_order_index\")-pl.col(\"order_index\"))).cast(pl.Float32))\n",
    "    .drop([\"order_index\", \"next_order_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each order-order pair\n",
    "order_to_order_count = (\n",
    "    subsequent_orders\n",
    "    .group_by([\"order_aid\", \"next_order_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each order\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_orders_total_count = (\n",
    "    subsequent_orders\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being ordered after another item has been ordered\n",
    "order_to_order_matrix = (\n",
    "    order_to_order_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"order_aid\", \"next_order_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_order_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_order_matrix.write_csv(\"./order_to_order_matrix_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Order to order whole sessions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (18_196_971, 3)\n",
      "┌───────────┬────────────────┬─────────────┐\n",
      "│ order_aid ┆ next_order_aid ┆ probability │\n",
      "│ ---       ┆ ---            ┆ ---         │\n",
      "│ u32       ┆ u32            ┆ f32         │\n",
      "╞═══════════╪════════════════╪═════════════╡\n",
      "│ 1836735   ┆ 1836735        ┆ 1.0         │\n",
      "│ 1835249   ┆ 1740171        ┆ 1.0         │\n",
      "│ 1798478   ┆ 1798478        ┆ 1.0         │\n",
      "│ 1718110   ┆ 1718110        ┆ 1.0         │\n",
      "│ 1673053   ┆ 37525          ┆ 1.0         │\n",
      "│ …         ┆ …              ┆ …           │\n",
      "│ 231487    ┆ 644882         ┆ 0.000001    │\n",
      "│ 846545    ┆ 1094510        ┆ 0.000001    │\n",
      "│ 756588    ┆ 1711735        ┆ 0.000001    │\n",
      "│ 846545    ┆ 444504         ┆ 0.000001    │\n",
      "│ 846545    ┆ 1252537        ┆ 0.000001    │\n",
      "└───────────┴────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "orders_df = (\n",
    "    df\n",
    "    .explode(\"events\")\n",
    "    .unnest(\"events\")\n",
    "    .sort([\"session\", \"ts\"], descending=[False, False])\n",
    "    .drop(\"ts\")\n",
    "    # Make groups based on types and then make sure that session boundaries are not crossed\n",
    "    .with_columns(group=(pl.col(\"type\") == \"orders\").rle_id().cast(pl.UInt32))\n",
    "    .with_columns(group=pl.struct(\"session\", \"group\").rle_id())\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .drop(\"type\")\n",
    "    # Remove multiple orders in the same group\n",
    "    .unique()\n",
    "    .lazy()\n",
    ")\n",
    "\n",
    "order_to_order = (\n",
    "    orders_df\n",
    "    .join(orders_df.rename({\"group\": \"next_group\", \"aid\": \"next_aid\"}), on=\"session\", how=\"inner\")\n",
    "    .filter(pl.col(\"group\") <= pl.col(\"next_group\"))\n",
    "    # Filter out same items ordered multiple times at the same time\n",
    "    .filter((pl.col(\"group\") != pl.col(\"next_group\")) | (pl.col(\"aid\") != pl.col(\"next_aid\")))\n",
    "    # time decay\n",
    "    .with_columns(weight = (1 / (pl.col(\"next_group\") - pl.col(\"group\") + 1)).cast(pl.Float32))\n",
    "    .drop([\"group\", \"next_group\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each order-order pair\n",
    "order_to_order_count = (\n",
    "    order_to_order\n",
    "    .group_by([\"aid\", \"next_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each order\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_orders_total_count = (\n",
    "    order_to_order\n",
    "    .group_by(\"aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being ordered after another item has been ordered\n",
    "order_to_order_matrix = (\n",
    "    order_to_order_count\n",
    "    .join(aid_orders_total_count, on=\"aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"aid\", \"next_aid\"])\n",
    "    .rename({\"aid\": \"order_aid\", \"next_aid\": \"next_order_aid\"})\n",
    "    .sort([\"probability\", \"order_aid\", \"next_order_aid\"], descending=True)\n",
    "    .collect(streaming=True)\n",
    ")\n",
    "\n",
    "print(order_to_order_matrix)\n",
    "order_to_order_matrix.write_csv(\"./order_to_order_matrix_whole_sessions_time_decay.csv\")\n",
    "\n",
    "\n",
    "# # Check that probabilities sum to the amount of unique aids\n",
    "# print(\"Unique aids:\", order_to_order_matrix.select(\"order_aid\").n_unique())\n",
    "# print(\"Total probability:\", order_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Order incompatibility matrix\n",
    "Order incompatibility matrix is defined as links between items which are often ordered with same items but are never ordered together."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2_041_966, 5)\n",
      "┌─────────┬─────────────────────────────┬─────────────────────────────┬──────────┬─────────────────┐\n",
      "│ aid     ┆ session                     ┆ ts                          ┆ order_id ┆ aid_order_count │\n",
      "│ ---     ┆ ---                         ┆ ---                         ┆ ---      ┆ ---             │\n",
      "│ u32     ┆ list[u32]                   ┆ list[u32]                   ┆ u32      ┆ u32             │\n",
      "╞═════════╪═════════════════════════════╪═════════════════════════════╪══════════╪═════════════════╡\n",
      "│ 543308  ┆ [20, 611179, … 13662569]    ┆ [1661552940, 1660733747, …  ┆ 0        ┆ 55              │\n",
      "│         ┆                             ┆ 166…                        ┆          ┆                 │\n",
      "│ 1670763 ┆ [45, 99348, … 13713227]     ┆ [1660567026, 1661601399, …  ┆ 1        ┆ 54              │\n",
      "│         ┆                             ┆ 166…                        ┆          ┆                 │\n",
      "│ 772148  ┆ [47, 30771, … 13862652]     ┆ [1661024972, 1661620424, …  ┆ 2        ┆ 64              │\n",
      "│         ┆                             ┆ 166…                        ┆          ┆                 │\n",
      "│ 791627  ┆ [49, 25533, … 13858809]     ┆ [1661186508, 1660957386, …  ┆ 3        ┆ 315             │\n",
      "│         ┆                             ┆ 166…                        ┆          ┆                 │\n",
      "│ 228850  ┆ [58, 1789477, … 13821606]   ┆ [1660737966, 1661081590, …  ┆ 4        ┆ 22              │\n",
      "│         ┆                             ┆ 166…                        ┆          ┆                 │\n",
      "│ …       ┆ …                           ┆ …                           ┆ …        ┆ …               │\n",
      "│ 1766353 ┆ [28573, 227584, … 13924999] ┆ [1661606147, 1661169545, …  ┆ 1195275  ┆ 54              │\n",
      "│         ┆                             ┆ 166…                        ┆          ┆                 │\n",
      "│ 1488793 ┆ [99233, 191004, … 13925151] ┆ [1661598320, 1661620712, …  ┆ 1195276  ┆ 201             │\n",
      "│         ┆                             ┆ 166…                        ┆          ┆                 │\n",
      "│ 1599360 ┆ [925364, 2587520, …         ┆ [1661147865, 1661006126, …  ┆ 1195276  ┆ 17              │\n",
      "│         ┆ 13925151]                   ┆ 166…                        ┆          ┆                 │\n",
      "│ 996393  ┆ [3864040, 6056579, …        ┆ [1661286075, 1661507397, …  ┆ 1195276  ┆ 12              │\n",
      "│         ┆ 13925151]                   ┆ 166…                        ┆          ┆                 │\n",
      "│ 956231  ┆ [4465908, 6723573, …        ┆ [1661682251, 1661531800, …  ┆ 1195276  ┆ 7               │\n",
      "│         ┆ 13925151]                   ┆ 166…                        ┆          ┆                 │\n",
      "└─────────┴─────────────────────────────┴─────────────────────────────┴──────────┴─────────────────┘\n",
      "shape: (9, 2)\n",
      "┌────────────┬─────────────────┐\n",
      "│ statistic  ┆ aid_order_count │\n",
      "│ ---        ┆ ---             │\n",
      "│ str        ┆ f64             │\n",
      "╞════════════╪═════════════════╡\n",
      "│ count      ┆ 2.041966e6      │\n",
      "│ null_count ┆ 0.0             │\n",
      "│ mean       ┆ 77.278376       │\n",
      "│ std        ┆ 168.97202       │\n",
      "│ min        ┆ 2.0             │\n",
      "│ 25%        ┆ 7.0             │\n",
      "│ 50%        ┆ 20.0            │\n",
      "│ 75%        ┆ 67.0            │\n",
      "│ max        ┆ 1649.0          │\n",
      "└────────────┴─────────────────┘\n",
      "shape: (327_300, 6)\n",
      "┌─────────┬─────────┬───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
      "│ aid_1   ┆ aid_2   ┆ order_id          ┆ aid_1_order_count ┆ aid_2_order_count ┆ aid_pair_order_c │\n",
      "│ ---     ┆ ---     ┆ ---               ┆ ---               ┆ ---               ┆ ount             │\n",
      "│ u32     ┆ u32     ┆ list[u32]         ┆ list[u32]         ┆ list[u32]         ┆ ---              │\n",
      "│         ┆         ┆                   ┆                   ┆                   ┆ u32              │\n",
      "╞═════════╪═════════╪═══════════════════╪═══════════════════╪═══════════════════╪══════════════════╡\n",
      "│ 1302234 ┆ 1647157 ┆ [2426, 27967, …   ┆ [528, 528, … 528] ┆ [680, 680, … 680] ┆ 225              │\n",
      "│         ┆         ┆ 1190916]          ┆                   ┆                   ┆                  │\n",
      "│ 1647157 ┆ 1302234 ┆ [2426, 27967, …   ┆ [680, 680, … 680] ┆ [528, 528, … 528] ┆ 225              │\n",
      "│         ┆         ┆ 1190916]          ┆                   ┆                   ┆                  │\n",
      "│ 576949  ┆ 1647157 ┆ [18982, 23210, …  ┆ [466, 466, … 466] ┆ [680, 680, … 680] ┆ 178              │\n",
      "│         ┆         ┆ 1175630]          ┆                   ┆                   ┆                  │\n",
      "│ 1647157 ┆ 576949  ┆ [18982, 23210, …  ┆ [680, 680, … 680] ┆ [466, 466, … 466] ┆ 178              │\n",
      "│         ┆         ┆ 1175630]          ┆                   ┆                   ┆                  │\n",
      "│ 933686  ┆ 1446430 ┆ [2292, 5829, …    ┆ [268, 268, … 268] ┆ [255, 255, … 255] ┆ 169              │\n",
      "│         ┆         ┆ 1193762]          ┆                   ┆                   ┆                  │\n",
      "│ …       ┆ …       ┆ …                 ┆ …                 ┆ …                 ┆ …                │\n",
      "│ 1315485 ┆ 571762  ┆ [313953, 593597]  ┆ [85, 85]          ┆ [248, 248]        ┆ 2                │\n",
      "│ 738641  ┆ 558455  ┆ [358030, 364688]  ┆ [21, 21]          ┆ [26, 26]          ┆ 2                │\n",
      "│ 703517  ┆ 318045  ┆ [212310, 555577]  ┆ [33, 33]          ┆ [37, 37]          ┆ 2                │\n",
      "│ 1332991 ┆ 906597  ┆ [232111, 292605]  ┆ [180, 180]        ┆ [211, 211]        ┆ 2                │\n",
      "│ 1007654 ┆ 93650   ┆ [650823, 738062]  ┆ [34, 34]          ┆ [43, 43]          ┆ 2                │\n",
      "└─────────┴─────────┴───────────────────┴───────────────────┴───────────────────┴──────────────────┘\n",
      "shape: (9, 2)\n",
      "┌────────────┬──────────────────────┐\n",
      "│ statistic  ┆ aid_pair_order_count │\n",
      "│ ---        ┆ ---                  │\n",
      "│ str        ┆ f64                  │\n",
      "╞════════════╪══════════════════════╡\n",
      "│ count      ┆ 327300.0             │\n",
      "│ null_count ┆ 0.0                  │\n",
      "│ mean       ┆ 2.974067             │\n",
      "│ std        ┆ 3.427223             │\n",
      "│ min        ┆ 2.0                  │\n",
      "│ 25%        ┆ 2.0                  │\n",
      "│ 50%        ┆ 2.0                  │\n",
      "│ 75%        ┆ 3.0                  │\n",
      "│ max        ┆ 225.0                │\n",
      "└────────────┴──────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "grouped_orders = (\n",
    "    df\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    # Group orders by session and timestamp\n",
    "    .with_columns(order_id=pl.struct(\"session\", \"ts\").rle_id().cast(pl.UInt32))\n",
    "    .drop(\"type\")\n",
    "    # Remove duplicates from same order\n",
    "    .unique(subset=[\"order_id\", \"aid\"], maintain_order=True)\n",
    "    # Count in how many orders each aid appears\n",
    "    .group_by(\"aid\", maintain_order=True)\n",
    "    .agg(pl.exclude(\"aid\"), pl.len().alias(\"aid_order_count\"))\n",
    "    # Filter out aids with very few orders\n",
    "    .filter(pl.col(\"aid_order_count\") > 1)\n",
    "    .explode([\"order_id\"])\n",
    "    .sort([\"order_id\"])\n",
    ")\n",
    "\n",
    "print(grouped_orders)\n",
    "print(grouped_orders.select(\"aid_order_count\").describe())\n",
    "\n",
    "order_pairs = (\n",
    "    grouped_orders\n",
    "    .drop([\"session\", \"ts\"])\n",
    "    .rename({\"aid\": \"aid_1\", \"aid_order_count\": \"aid_1_order_count\"})\n",
    "    .join(grouped_orders.drop([\"session\", \"ts\"]).rename({\"aid\": \"aid_2\", \"aid_order_count\": \"aid_2_order_count\"}), on=\"order_id\", how=\"inner\")\n",
    "    .filter(pl.col(\"aid_1\") != pl.col(\"aid_2\"))\n",
    "    .group_by([\"aid_1\", \"aid_2\"])\n",
    "    .agg(pl.all(), pl.len().alias(\"aid_pair_order_count\"))\n",
    "    # Filter out aid pairs with very few orders\n",
    "    .filter(pl.col(\"aid_pair_order_count\") > 1)\n",
    "    .sort(\"aid_pair_order_count\", descending=True)\n",
    ")\n",
    "\n",
    "print(order_pairs)\n",
    "print(order_pairs.select(\"aid_pair_order_count\").describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8_850, 2)\n",
      "┌───────────┬─────────────────────────────┐\n",
      "│ order_aid ┆ context                     │\n",
      "│ ---       ┆ ---                         │\n",
      "│ u32       ┆ list[u32]                   │\n",
      "╞═══════════╪═════════════════════════════╡\n",
      "│ 1328763   ┆ [70160, 169149, … 1747792]  │\n",
      "│ 985351    ┆ [53600, 83604, … 1839274]   │\n",
      "│ 174368    ┆ [174368, 258074, … 1836036] │\n",
      "│ 1095186   ┆ [215620, 284139, … 1796802] │\n",
      "│ 342019    ┆ [6851, 18185, … 1805466]    │\n",
      "│ …         ┆ …                           │\n",
      "│ 258074    ┆ [174368, 258074, … 1836036] │\n",
      "│ 954655    ┆ [26525, 76799, … 1683038]   │\n",
      "│ 557988    ┆ [557988, 1487177]           │\n",
      "│ 909668    ┆ [314514, 411195, … 1840890] │\n",
      "│ 1589314   ┆ [718019, 807430, … 1833626] │\n",
      "└───────────┴─────────────────────────────┘\n",
      "Start\n",
      "Done\n",
      "\n",
      "shape: (219, 2)\n",
      "┌─────────┬──────────────────┐\n",
      "│ aid     ┆ incompatible_aid │\n",
      "│ ---     ┆ ---              │\n",
      "│ u32     ┆ u32              │\n",
      "╞═════════╪══════════════════╡\n",
      "│ 1619389 ┆ 1336095          │\n",
      "│ 1731425 ┆ 901329           │\n",
      "│ 1614415 ┆ 1612613          │\n",
      "│ 433861  ┆ 1123561          │\n",
      "│ 1556265 ┆ 1284071          │\n",
      "│ …       ┆ …                │\n",
      "│ 1697138 ┆ 79965            │\n",
      "│ 862629  ┆ 1730459          │\n",
      "│ 798391  ┆ 1534257          │\n",
      "│ 464451  ┆ 1631472          │\n",
      "│ 666500  ┆ 1066247          │\n",
      "└─────────┴──────────────────┘\n",
      "shape: (135, 2)\n",
      "┌─────────┬──────────────────┐\n",
      "│ aid     ┆ incompatible_aid │\n",
      "│ ---     ┆ ---              │\n",
      "│ u32     ┆ u32              │\n",
      "╞═════════╪══════════════════╡\n",
      "│ 3       ┆ 1180285          │\n",
      "│ 15170   ┆ 662924           │\n",
      "│ 15170   ┆ 751283           │\n",
      "│ 15170   ┆ 1494074          │\n",
      "│ 35435   ┆ 901329           │\n",
      "│ …       ┆ …                │\n",
      "│ 1771163 ┆ 1730459          │\n",
      "│ 1823013 ┆ 1158258          │\n",
      "│ 1830582 ┆ 326682           │\n",
      "│ 1840418 ┆ 742592           │\n",
      "│ 1853232 ┆ 158571           │\n",
      "└─────────┴──────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# orders and clicks preceding orders are grouped together\n",
    "grouped_orders_and_clicks = (\n",
    "    df\n",
    "    .sort([\"session\", \"ts\"])\n",
    "    .filter(pl.col(\"type\") != \"carts\")\n",
    "    # Filter out sessions with no orders\n",
    "    .group_by(\"session\")\n",
    "    .agg(pl.all(), pl.col(\"type\").filter(pl.col(\"type\") == \"orders\").n_unique().alias(\"has_orders\"))\n",
    "    .filter(pl.col(\"has_orders\") == 1)\n",
    "    .drop(\"has_orders\")\n",
    "    .explode([\"aid\", \"ts\", \"type\"])\n",
    "    # Group orders and clicks\n",
    "    .with_columns(order_timestamp_mask=pl.when(pl.col(\"type\") == \"orders\").then(pl.col(\"ts\")).otherwise(0).cast(pl.UInt32))\n",
    "    .with_columns(group=pl.struct(\"session\", \"order_timestamp_mask\").rle_id().cast(pl.UInt32))\n",
    "    .with_columns(group=pl.when(pl.col(\"type\") == \"clicks\").then(pl.col(\"group\") + 1).otherwise(pl.col(\"group\")))\n",
    "    .drop([\"order_timestamp_mask\", \"session\", \"ts\"])\n",
    "    # Remove duplicate clicks and orders of groups\n",
    "    .unique(maintain_order=True)\n",
    ")\n",
    "\n",
    "# Used for checking that items which share context have not been ordered together\n",
    "aids_ordered_together = (\n",
    "    grouped_orders_and_clicks\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .drop(\"type\")\n",
    "    .rename({\"aid\": \"aid_1\"})\n",
    "    .join(grouped_orders_and_clicks.filter(pl.col(\"type\") == \"orders\").drop(\"type\").rename({\"aid\": \"aid_2\"}), on=\"group\", how=\"inner\")\n",
    "    .filter(pl.col(\"aid_1\") != pl.col(\"aid_2\"))\n",
    "    .group_by([\"aid_1\", \"aid_2\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    # TODO: Play around with this value. How many can be considered as exception?\n",
    "    .filter(pl.col(\"count\") > 2)\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "# print(aids_ordered_together)\n",
    "\n",
    "# Used for determining which aids have enough orders to be considered for incompatibility\n",
    "top_n_ordered_aids = 0.02\n",
    "aids_with_enough_orders = (\n",
    "    grouped_orders_and_clicks\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .drop([\"type\", \"group\"])\n",
    "    # Count in how many orders each aid appears\n",
    "    .group_by(\"aid\", maintain_order=True)\n",
    "    .agg(pl.len().alias(\"aid_order_count\"))\n",
    "    .sort(\"aid_order_count\", descending=True)\n",
    "    .filter(pl.col(\"aid_order_count\") > pl.col(\"aid_order_count\").quantile((1-top_n_ordered_aids), interpolation=\"midpoint\"))\n",
    "    .select(\"aid\")\n",
    ")\n",
    "\n",
    "\n",
    "# Remove aids that have too few orders\n",
    "# Both clicks and orders are removed to make sure that there is as little noise as possible\n",
    "grouped_orders_and_clicks = (\n",
    "    grouped_orders_and_clicks\n",
    "    .join(aids_with_enough_orders, on=\"aid\", how=\"semi\")\n",
    ")\n",
    "\n",
    "\n",
    "# Used for determining the similarity of items based on their context\n",
    "order_contexts = (\n",
    "    grouped_orders_and_clicks\n",
    "    .filter(pl.col(\"type\") == \"clicks\")\n",
    "    .drop(\"type\")\n",
    "    .rename({\"aid\": \"click_aid\"})\n",
    "    .join(grouped_orders_and_clicks.filter(pl.col(\"type\") == \"orders\").drop(\"type\").rename({\"aid\": \"order_aid\"}), on=\"group\", how=\"inner\")\n",
    "    .drop(\"group\")\n",
    "    .group_by([\"order_aid\", \"click_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    # Filter out pairs that appear only once meaning they are part of only one session\n",
    "    .filter(pl.col(\"count\") > 1)\n",
    "    # Create contexts\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.col(\"click_aid\").unique().sort().alias(\"context\"))\n",
    ")\n",
    "print(order_contexts)\n",
    "\n",
    "order_contexts_dict = (\n",
    "    order_contexts\n",
    "    .with_columns(order_aid=pl.col(\"order_aid\").cast(str))\n",
    "    .transpose(column_names=\"order_aid\")\n",
    "    .to_dict(as_series=False)\n",
    ")\n",
    "\n",
    "# Find all incompatible pairs by finding aids that have never been ordered together but have common aids that are often clicked before ordering\n",
    "candidate_incompatible_pairs = []\n",
    "\n",
    "order_context_rows = order_contexts.rows()\n",
    "len_order_context = len(order_context_rows)\n",
    "print(\"Start\")\n",
    "for index, row in enumerate(order_context_rows):\n",
    "    if (index+1) % 10000 == 0:\n",
    "        print(f\"row {index+1} / {len_order_context}\")\n",
    "\n",
    "    order_aid = row[0]\n",
    "    order_aid_context = row[1]\n",
    "\n",
    "    for click_aid in order_aid_context:\n",
    "        click_aid_context = order_contexts_dict.get(str(click_aid))\n",
    "        if click_aid_context is not None:\n",
    "            click_aid_context = click_aid_context[0]\n",
    "            # Jaccard similarity\n",
    "            similarity = len(set(order_aid_context).intersection(click_aid_context)) / len(set(order_aid_context).union(click_aid_context))\n",
    "            if similarity > 0.8:\n",
    "                candidate_incompatible_pairs.append((order_aid, click_aid))\n",
    "\n",
    "print(\"Done\")\n",
    "print()\n",
    "\n",
    "incompatible_df = (\n",
    "    pl.DataFrame(\n",
    "        data=candidate_incompatible_pairs,\n",
    "        orient='row',\n",
    "        schema={\"aid\": pl.UInt32, \"incompatible_aid\": pl.UInt32}\n",
    "    )\n",
    "    .filter(pl.col(\"aid\") != pl.col(\"incompatible_aid\"))\n",
    "    .unique()\n",
    ")\n",
    "print(incompatible_df)\n",
    "\n",
    "incompatible_df = (\n",
    "    incompatible_df\n",
    "    # Filter out pairs that are too often bought together\n",
    "    .join(aids_ordered_together, left_on=[\"aid\", \"incompatible_aid\"], right_on=[\"aid_1\", \"aid_2\"], how=\"anti\")\n",
    "    .sort([\"aid\", \"incompatible_aid\"])\n",
    ")\n",
    "print(incompatible_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "incompatible_df.write_csv(\"./incompatible_matrix_7.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
