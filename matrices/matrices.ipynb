{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Item relation matrices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (12_899_779, 2)\n",
      "┌──────────┬─────────────────────────────────┐\n",
      "│ session  ┆ events                          │\n",
      "│ ---      ┆ ---                             │\n",
      "│ u32      ┆ list[struct[3]]                 │\n",
      "╞══════════╪═════════════════════════════════╡\n",
      "│ 0        ┆ [{1517085,1659304800025,\"click… │\n",
      "│ 1        ┆ [{424964,1659304800025,\"carts\"… │\n",
      "│ 2        ┆ [{763743,1659304800038,\"clicks… │\n",
      "│ 3        ┆ [{1425967,1659304800095,\"carts… │\n",
      "│ 4        ┆ [{613619,1659304800119,\"clicks… │\n",
      "│ …        ┆ …                               │\n",
      "│ 12899774 ┆ [{33035,1661723968869,\"clicks\"… │\n",
      "│ 12899775 ┆ [{1743151,1661723970935,\"click… │\n",
      "│ 12899776 ┆ [{548599,1661723972537,\"clicks… │\n",
      "│ 12899777 ┆ [{384045,1661723976974,\"clicks… │\n",
      "│ 12899778 ┆ [{561560,1661723983611,\"clicks… │\n",
      "└──────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# define the schema of the dataframe\n",
    "event_schema = pl.Struct({\"aid\": pl.UInt32, \"ts\": pl.UInt64, \"type\": str})\n",
    "df_schema = {\"session\": pl.UInt32, \"events\": pl.List(event_schema)}\n",
    "\n",
    "df = pl.read_ndjson('../data/train.jsonl', schema=df_schema, low_memory=True)\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (216_716_096, 4)\n",
      "┌──────────┬─────────┬───────────────┬────────┐\n",
      "│ session  ┆ aid     ┆ ts            ┆ type   │\n",
      "│ ---      ┆ ---     ┆ ---           ┆ ---    │\n",
      "│ u32      ┆ u32     ┆ u64           ┆ str    │\n",
      "╞══════════╪═════════╪═══════════════╪════════╡\n",
      "│ 0        ┆ 1517085 ┆ 1659304800025 ┆ clicks │\n",
      "│ 0        ┆ 1563459 ┆ 1659304904511 ┆ clicks │\n",
      "│ 0        ┆ 1309446 ┆ 1659367439426 ┆ clicks │\n",
      "│ 0        ┆ 16246   ┆ 1659367719997 ┆ clicks │\n",
      "│ 0        ┆ 1781822 ┆ 1659367871344 ┆ clicks │\n",
      "│ …        ┆ …       ┆ …             ┆ …      │\n",
      "│ 12899776 ┆ 1737908 ┆ 1661723987073 ┆ clicks │\n",
      "│ 12899777 ┆ 384045  ┆ 1661723976974 ┆ clicks │\n",
      "│ 12899777 ┆ 384045  ┆ 1661723986800 ┆ clicks │\n",
      "│ 12899778 ┆ 561560  ┆ 1661723983611 ┆ clicks │\n",
      "│ 12899778 ┆ 32070   ┆ 1661723994936 ┆ clicks │\n",
      "└──────────┴─────────┴───────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Sessions\n",
    "exploded_df = (\n",
    "    df\n",
    "    .explode(\"events\")\n",
    "    .unnest(\"events\")\n",
    ")\n",
    "\n",
    "print(exploded_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_sub_sessions(with_next_event=True, only_clicks=False, with_row_index=False, limit=None):\n",
    "    \"\"\"\n",
    "    Splits sessions into sub sessions based on time between events or session boundaries.\n",
    "\n",
    "    Args:\n",
    "        with_next_event: whether rows should include consecutive events or not.\n",
    "        only_clicks: only clicks are considered in the sub sessions\n",
    "        with_row_index: add row index to the sub sessions in order to calculate delta time between events\n",
    "        limit: limit the amount of rows to be processed.\n",
    "\n",
    "    Returns: DataFrame of sub sessions\n",
    "    \"\"\"\n",
    "\n",
    "    sub_sessions = exploded_df\n",
    "\n",
    "    if limit is not None:\n",
    "        sub_sessions = exploded_df.limit(limit)\n",
    "    if only_clicks:\n",
    "        sub_sessions = sub_sessions.filter(pl.col(\"type\") == \"clicks\")\n",
    "\n",
    "    sub_sessions = (\n",
    "        sub_sessions\n",
    "        # Convert ts to seconds and cast to UInt32 to save memory\n",
    "        .with_columns((pl.col(\"ts\")//1000).cast(pl.UInt32))\n",
    "        .sort([\"session\", \"ts\"])\n",
    "        .with_columns(\n",
    "            next_session = pl.col(\"session\").shift(-1),\n",
    "            next_aid = pl.col(\"aid\").shift(-1),\n",
    "            next_ts = pl.col(\"ts\").shift(-1),\n",
    "            next_type = pl.col(\"type\").shift(-1),\n",
    "        )\n",
    "        # Row is a sub session boundary if there is existing session boundary or if time between events is more than 30 minutes\n",
    "        .with_columns(\n",
    "            is_session_boundary = ((pl.col(\"session\") != pl.col(\"next_session\")) | (pl.col(\"next_ts\") - pl.col(\"ts\") > 1800)),\n",
    "        )\n",
    "        .with_columns(\n",
    "            sub_session = pl.col(\"is_session_boundary\").cum_sum().cast(pl.UInt32),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Use this when immediate next event is required\n",
    "    # Last event of sub session is always found in the same row as the second last\n",
    "    if with_next_event:\n",
    "        sub_sessions = (\n",
    "            sub_sessions\n",
    "            # Filter out session boundaries. This also removes sub sessions with only 1 event which are not interesting\n",
    "            .filter(pl.col(\"is_session_boundary\").not_())\n",
    "            .drop(\"is_session_boundary\")\n",
    "        )\n",
    "    # Use this when all events are wanted to be found in their own rows and single column\n",
    "    else:\n",
    "        sub_sessions = (\n",
    "            sub_sessions\n",
    "            # Keep each event in their own row\n",
    "            .with_columns(sub_session = pl.when(pl.col(\"is_session_boundary\")).then(pl.col(\"sub_session\") - 1).otherwise(pl.col(\"sub_session\")))\n",
    "            .drop([\"session\", \"next_session\", \"next_aid\", \"next_ts\", \"next_type\", \"is_session_boundary\"])\n",
    "            .filter(pl.col(\"sub_session\").is_null().not_())\n",
    "        )\n",
    "\n",
    "        # Filter out sub session with only one event\n",
    "        multi_event_sub_sessions = (\n",
    "            sub_sessions\n",
    "            .group_by(\"sub_session\")\n",
    "            .agg(pl.len())\n",
    "            .filter(pl.col(\"len\") > 1)\n",
    "            .select(\"sub_session\")\n",
    "        )\n",
    "\n",
    "        sub_sessions = (\n",
    "            sub_sessions\n",
    "            .join(multi_event_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "        )\n",
    "\n",
    "    if with_row_index:\n",
    "        sub_sessions = sub_sessions.with_row_index()\n",
    "\n",
    "    return sub_sessions\n",
    "\n",
    "# sub_sessions = get_sub_sessions()\n",
    "# print(sub_sessions)\n",
    "# print(\"Amount of sub sessions:\", sub_sessions.select(\"sub_session\").n_unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# Note there should only be used when sub_session are generated with param with_next_event=False\n",
    "# Otherwise some events are lost\n",
    "\n",
    "def get_clicks_of_sub_session(sub_sessions):\n",
    "    return (\n",
    "        sub_sessions\n",
    "        .filter(pl.col(\"type\") == \"clicks\")\n",
    "        .select([\"sub_session\", \"ts\", \"aid\"])\n",
    "        .rename({\"ts\": \"click_ts\", \"aid\": \"click_aid\"})\n",
    "    )\n",
    "\n",
    "def get_carts_of_sub_session(sub_sessions):\n",
    "    return (\n",
    "        sub_sessions\n",
    "        .filter(pl.col(\"type\") == \"carts\")\n",
    "        .select([\"sub_session\", \"ts\", \"aid\"])\n",
    "        .rename({\"ts\": \"cart_ts\", \"aid\": \"cart_aid\"})\n",
    "    )\n",
    "\n",
    "def get_orders_of_sub_session(sub_sessions):\n",
    "    return (\n",
    "        sub_sessions\n",
    "        .filter(pl.col(\"type\") == \"orders\")\n",
    "        .select([\"sub_session\", \"ts\", \"aid\"])\n",
    "        .rename({\"ts\": \"order_ts\", \"aid\": \"order_aid\"})\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Click to click matrix\n",
    "Click to click matrix is defined as the probabilities of other aids being clicked after the previous aid is clicked.\n",
    "Click to click matrix is formed from the sub sessions since there is no point in counting subsequent clicks that are from a user coming back to site after a long time\n",
    "\n",
    "We do multiple variations of the click to click matrix:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next click only"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions()\n",
    "\n",
    "# Count how many same click to click events there are\n",
    "subsequent_clicks_count = (\n",
    "    sub_sessions\n",
    "    .filter((pl.col(\"type\") == \"clicks\") & (pl.col(\"next_type\") == \"clicks\"))\n",
    "    .group_by([\"aid\", \"next_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    ")\n",
    "\n",
    "# Sum all the clicks for each aid\n",
    "aid_clicks_total_count = (\n",
    "    subsequent_clicks_count\n",
    "    .group_by(\"aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being clicked immediately after another item has been clicked\n",
    "click_to_click_matrix = (\n",
    "    subsequent_clicks_count\n",
    "    .join(aid_clicks_total_count, on=\"aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"aid\", \"next_aid\"])\n",
    "    .rename({\"aid\": \"click_aid\", \"next_aid\": \"next_click_aid\"})\n",
    ")\n",
    "\n",
    "print(click_to_click_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", click_to_click_matrix.select(\"aid\").n_unique())\n",
    "print(\"Total probability:\", click_to_click_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "click_to_click_matrix.write_csv(\"./click_to_click_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next click only. Remove carts and orders from the sub sessions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(only_clicks=True)\n",
    "\n",
    "# Count how many same click to click events there are\n",
    "subsequent_clicks_count = (\n",
    "    sub_sessions\n",
    "    .group_by([\"aid\", \"next_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    ")\n",
    "\n",
    "# Sum all the clicks for each aid\n",
    "aid_clicks_total_count = (\n",
    "    subsequent_clicks_count\n",
    "    .group_by(\"aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being clicked immediately after another item has been clicked\n",
    "click_to_click_matrix = (\n",
    "    subsequent_clicks_count\n",
    "    .join(aid_clicks_total_count, on=\"aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"aid\", \"next_aid\"])\n",
    "    .rename({\"aid\": \"click_aid\", \"next_aid\": \"next_click_aid\"})\n",
    ")\n",
    "\n",
    "print(click_to_click_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", click_to_click_matrix.select(\"aid\").n_unique())\n",
    "print(\"Total probability:\", click_to_click_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "click_to_click_matrix.write_csv(\"./click_to_click_matrix_only_clicks.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next two clicks with time decay. Remove carts and orders from the sub sessions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (200_096_794, 3)\n",
      "┌───────────┬─────────────┬─────────┐\n",
      "│ index     ┆ sub_session ┆ aid     │\n",
      "│ ---       ┆ ---         ┆ ---     │\n",
      "│ u32       ┆ u32         ┆ u32     │\n",
      "╞═══════════╪═════════════╪═════════╡\n",
      "│ 0         ┆ 12115466    ┆ 552662  │\n",
      "│ 1         ┆ 12115466    ┆ 871283  │\n",
      "│ 2         ┆ 12115466    ┆ 1436133 │\n",
      "│ 3         ┆ 12115466    ┆ 871283  │\n",
      "│ 4         ┆ 12115466    ┆ 1006139 │\n",
      "│ …         ┆ …           ┆ …       │\n",
      "│ 200096789 ┆ 2372394     ┆ 1283290 │\n",
      "│ 200096790 ┆ 2372394     ┆ 723240  │\n",
      "│ 200096791 ┆ 10679973    ┆ 1828755 │\n",
      "│ 200096792 ┆ 10679973    ┆ 1581840 │\n",
      "│ 200096793 ┆ 10679973    ┆ 63237   │\n",
      "└───────────┴─────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Read and manipulate data and then save it to csv in order to rest with streaming.\n",
    "# Running out of memory otherwise\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# define the schema of the dataframe\n",
    "event_schema = pl.Struct({\"aid\": pl.UInt32, \"ts\": pl.UInt64, \"type\": str})\n",
    "df_schema = {\"session\": pl.UInt32, \"events\": pl.List(event_schema)}\n",
    "\n",
    "sub_sessions = (\n",
    "    pl.read_ndjson('../data/train.jsonl', schema=df_schema, low_memory=True)\n",
    "    .explode(\"events\")\n",
    "    .unnest(\"events\")\n",
    "    # Convert ts to seconds and cast to UInt32 to save memory\n",
    "    .with_columns((pl.col(\"ts\")//1000).cast(pl.UInt32))\n",
    "    .sort([\"session\", \"ts\"])\n",
    "    .with_columns(\n",
    "        next_session = pl.col(\"session\").shift(-1),\n",
    "        next_aid = pl.col(\"aid\").shift(-1),\n",
    "        next_ts = pl.col(\"ts\").shift(-1),\n",
    "        next_type = pl.col(\"type\").shift(-1),\n",
    "    )\n",
    "    # Row is a sub session boundary if there is existing session boundary or if time between events is more than 1 hour\n",
    "    .with_columns(\n",
    "        is_session_boundary = ((pl.col(\"session\") != pl.col(\"next_session\")) | (pl.col(\"next_ts\") - pl.col(\"ts\") > 3600)),\n",
    "    )\n",
    "    .with_columns(\n",
    "        sub_session = pl.col(\"is_session_boundary\").cum_sum().cast(pl.UInt32),\n",
    "    )\n",
    "    # Keep each event in their own row\n",
    "    .with_columns(sub_session = pl.when(pl.col(\"is_session_boundary\")).then(pl.col(\"sub_session\") - 1).otherwise(pl.col(\"sub_session\")))\n",
    "    .drop([\"session\", \"ts\", \"type\", \"next_session\", \"next_aid\", \"next_ts\", \"next_type\", \"is_session_boundary\"])\n",
    "    .filter(pl.col(\"sub_session\").is_null().not_())\n",
    "    # Filter sub session with only one event\n",
    "    .group_by(pl.col(\"sub_session\"))\n",
    "    .agg(pl.col(\"aid\"))\n",
    "    .filter(pl.col(\"aid\").list.len() > 1)\n",
    "    .explode(\"aid\")\n",
    "    .with_row_index()\n",
    ")\n",
    "\n",
    "print(sub_sessions)\n",
    "\n",
    "# Save to csv\n",
    "sub_sessions.write_csv(\"./clicks/clicks_of_sub_sessions_1h.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The system cannot find the file specified. (os error 2): ./clicks/clicks_of_sub_sessions_1h.csv\n\nThis error occurred with the following context stack:\n\t[1] 'csv scan'\n\t[2] 'join left'\n\t[3] 'join'\n\t[4] 'with_columns'\n\t[5] 'filter'\n\t[6] 'with_columns'\n\t[7] 'format!(\"{}\", function).to_lowercase()'\n\t[8] 'group_by'\n\t[9] 'join left'\n\t[10] 'join'\n\t[11] 'with_columns'\n\t[12] 'format!(\"{}\", function).to_lowercase()'\n\t[13] 'sort'\n\t[14] 'format!(\"{}\", function).to_lowercase()'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 44\u001B[0m\n\u001B[0;32m     35\u001B[0m aid_clicks_total_count \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     36\u001B[0m     click_to_click_count\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;241m.\u001B[39mgroup_by(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maid\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;241m.\u001B[39magg(pl\u001B[38;5;241m.\u001B[39mcol(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweighted_count\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweighted_total_count\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m     39\u001B[0m )\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Calculate the probabilities of items being clicked after another item has been clicked\u001B[39;00m\n\u001B[0;32m     43\u001B[0m click_to_click_matrix \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m---> 44\u001B[0m     \u001B[43mclick_to_click_count\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43maid_clicks_total_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minner\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwith_columns\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprobability\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweighted_count\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweighted_total_count\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweighted_count\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweighted_total_count\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnext_aid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrename\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mclick_aid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnext_aid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnext_click_aid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstreaming\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m )\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28mprint\u001B[39m(click_to_click_matrix)\n",
      "File \u001B[1;32m~\\.virtualenvs\\recsys-dataset-onFW_Sex\\lib\\site-packages\\polars\\lazyframe\\frame.py:2021\u001B[0m, in \u001B[0;36mLazyFrame.collect\u001B[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001B[0m\n\u001B[0;32m   2019\u001B[0m \u001B[38;5;66;03m# Only for testing purposes\u001B[39;00m\n\u001B[0;32m   2020\u001B[0m callback \u001B[38;5;241m=\u001B[39m _kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost_opt_callback\u001B[39m\u001B[38;5;124m\"\u001B[39m, callback)\n\u001B[1;32m-> 2021\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrap_df(\u001B[43mldf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: The system cannot find the file specified. (os error 2): ./clicks/clicks_of_sub_sessions_1h.csv\n\nThis error occurred with the following context stack:\n\t[1] 'csv scan'\n\t[2] 'join left'\n\t[3] 'join'\n\t[4] 'with_columns'\n\t[5] 'filter'\n\t[6] 'with_columns'\n\t[7] 'format!(\"{}\", function).to_lowercase()'\n\t[8] 'group_by'\n\t[9] 'join left'\n\t[10] 'join'\n\t[11] 'with_columns'\n\t[12] 'format!(\"{}\", function).to_lowercase()'\n\t[13] 'sort'\n\t[14] 'format!(\"{}\", function).to_lowercase()'\n"
     ]
    }
   ],
   "source": [
    "# Run computations in streaming mode in order to not run out of memory\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "n_subsequent_clicks = 7\n",
    "\n",
    "df_schema = {\n",
    "    \"index\": pl.UInt32,\n",
    "    \"sub_session\": pl.UInt32,\n",
    "    \"aid\": pl.UInt32\n",
    "}\n",
    "\n",
    "subsequent_clicks = (\n",
    "    pl.scan_csv(\"./clicks/clicks_of_sub_sessions_1h.csv\", schema=df_schema)\n",
    "    .join(\n",
    "        pl.scan_csv(\"./clicks/clicks_of_sub_sessions_1h.csv\", schema=df_schema).rename({\"index\": \"next_index\", \"aid\": \"next_aid\"}),\n",
    "        on=\"sub_session\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .with_columns(delta_index=(pl.col(\"next_index\") - pl.col(\"index\")))\n",
    "    .filter((pl.col(\"delta_index\") >= 1) & (pl.col(\"delta_index\") <= n_subsequent_clicks))\n",
    "    .with_columns(weight=(1/pl.col(\"delta_index\")).cast(pl.Float32))\n",
    "    .drop([\"index\", \"next_index\", \"sub_session\", \"delta_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each click-click pair\n",
    "click_to_click_count = (\n",
    "    subsequent_clicks\n",
    "    .group_by([\"aid\", \"next_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each click\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_clicks_total_count = (\n",
    "    click_to_click_count\n",
    "    .group_by(\"aid\")\n",
    "    .agg(pl.col(\"weighted_count\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the probabilities of items being clicked after another item has been clicked\n",
    "click_to_click_matrix = (\n",
    "    click_to_click_count\n",
    "    .join(aid_clicks_total_count, on=\"aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"aid\", \"next_aid\"])\n",
    "    .rename({\"aid\": \"click_aid\", \"next_aid\": \"next_click_aid\"})\n",
    "    .collect(streaming=True)\n",
    ")\n",
    "\n",
    "print(click_to_click_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", click_to_click_matrix.select(\"click_aid\").n_unique())\n",
    "print(\"Total probability:\", click_to_click_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "click_to_click_matrix.write_csv(\"./click_to_click_matrix_only_clicks_time_decay_7_1h.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Click to cart matrix\n",
    "Click to cart matrix is defined as the probabilities of other aids being added to cart in the same sub session after an aid is clicked.\n",
    "Click to cart matrix is formed from the sub sessions since the sub session should show clear intent of the user to buy items they click."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get clicks and carts of sub sessions\n",
    "clicks_of_sub_sessions = get_clicks_of_sub_session(sub_sessions)\n",
    "\n",
    "carts_of_sub_sessions = get_carts_of_sub_session(sub_sessions)\n",
    "\n",
    "carts_after_clicks_in_sub_sessions = (\n",
    "    carts_of_sub_sessions\n",
    "    # Combine clicks and carts of sub sessions\n",
    "    .join(clicks_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only carts that happened after clicks\n",
    "    .filter(pl.col(\"click_ts\") < pl.col(\"cart_ts\"))\n",
    "    .select([\"sub_session\", \"click_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same click to cart events there are\n",
    "click_to_cart_count = (\n",
    "    carts_after_clicks_in_sub_sessions\n",
    "    .group_by([\"click_aid\", \"cart_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the clicks for each aid\n",
    "aid_clicks_total_count = (\n",
    "    click_to_cart_count\n",
    "    .group_by(\"click_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being added to cart after another item has been clicked\n",
    "click_to_cart_matrix = (\n",
    "    click_to_cart_count\n",
    "    .join(aid_clicks_total_count, on=\"click_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"click_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "print(click_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", click_to_cart_matrix.select(\"click_aid\").n_unique())\n",
    "print(\"Total probability:\", click_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "click_to_cart_matrix.write_csv(\"./click_to_cart_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Click to cart with time decay. Carts happening later in the session count less into the probability than carts that are closer to the click.\n",
    "The first cart relative to the clicked aid has weight of 1, second has weight of 1/2, third 1/3, etc..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = (\n",
    "    get_sub_sessions(with_next_event=False)\n",
    "    # Filter out orders\n",
    "    .filter(pl.col(\"type\") != \"orders\")\n",
    "    .with_columns(index=(pl.col(\"sub_session\") + (pl.col(\"type\") == \"carts\").cum_sum()))\n",
    ")\n",
    "\n",
    "# Get clicks and carts of sub sessions\n",
    "clicks_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"clicks\")\n",
    "    .rename({\"ts\": \"click_ts\", \"aid\": \"click_aid\", \"index\": \"click_index\"})\n",
    ")\n",
    "\n",
    "carts_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"carts\")\n",
    "    .rename({\"ts\": \"cart_ts\", \"aid\": \"cart_aid\", \"index\": \"cart_index\"})\n",
    ")\n",
    "\n",
    "carts_after_clicks_in_sub_sessions = (\n",
    "    carts_of_sub_sessions\n",
    "    # Combine clicks and carts of sub sessions\n",
    "    .join(clicks_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only carts that happened after clicks\n",
    "    .filter(pl.col(\"click_ts\") < pl.col(\"cart_ts\"))\n",
    "    .select([\"sub_session\", \"click_aid\", \"cart_aid\", \"click_index\", \"cart_index\"])\n",
    "    # Weight the click-to-cart relation based in index. Next cart has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"cart_index\")-pl.col(\"click_index\"))).cast(pl.Float32))\n",
    "    .drop([\"click_index\", \"cart_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each click-cart pair\n",
    "click_to_cart_count = (\n",
    "    carts_after_clicks_in_sub_sessions\n",
    "    .group_by([\"click_aid\", \"cart_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each click\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_clicks_total_count = (\n",
    "    carts_after_clicks_in_sub_sessions\n",
    "    .group_by(\"click_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being added to cart after another item has been clicked\n",
    "click_to_cart_matrix = (\n",
    "    click_to_cart_count\n",
    "    .join(aid_clicks_total_count, on=\"click_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"click_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "print(click_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", click_to_cart_matrix.select(\"click_aid\").n_unique())\n",
    "print(\"Total probability:\", click_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "click_to_cart_matrix.write_csv(\"./click_to_cart_matrix_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Click to order matrix\n",
    "Click to order matrix is defined as the probabilities of other aids being ordered in the same sub session after an aid is clicked.\n",
    "Click to order matrix is formed from the sub sessions since the sub session should show clear intent of the user to buy items they click."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get clicks and orders of sub sessions\n",
    "clicks_of_sub_sessions = get_clicks_of_sub_session(sub_sessions)\n",
    "\n",
    "orders_of_sub_sessions = get_orders_of_sub_session(sub_sessions)\n",
    "\n",
    "orders_after_clicks_in_sub_sessions = (\n",
    "    orders_of_sub_sessions\n",
    "    # Combine clicks and orders of sub sessions\n",
    "    .join(clicks_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only orders that happened after clicks\n",
    "    .filter(pl.col(\"click_ts\") < pl.col(\"order_ts\"))\n",
    "    .select([\"sub_session\", \"click_aid\", \"order_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same click to order events there are\n",
    "click_to_order_count = (\n",
    "    orders_after_clicks_in_sub_sessions\n",
    "    .group_by([\"click_aid\", \"order_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the clicks for each aid\n",
    "aid_clicks_total_count = (\n",
    "    click_to_order_count\n",
    "    .group_by(\"click_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being ordered after another item has been clicked\n",
    "click_to_order_matrix = (\n",
    "    click_to_order_count\n",
    "    .join(aid_clicks_total_count, on=\"click_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"click_aid\", \"order_aid\"])\n",
    ")\n",
    "\n",
    "print(click_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", click_to_order_matrix.select(\"click_aid\").n_unique())\n",
    "print(\"Total probability:\", click_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "click_to_order_matrix.write_csv(\"./click_to_order_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Click to order with time decay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = (\n",
    "    get_sub_sessions(with_next_event=False)\n",
    "    # Filter out carts\n",
    "    .filter(pl.col(\"type\") != \"carts\")\n",
    "    .with_columns(index=(pl.col(\"sub_session\") + (pl.col(\"type\") == \"orders\").cum_sum()))\n",
    ")\n",
    "\n",
    "# Get clicks and orders of sub sessions\n",
    "clicks_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"clicks\")\n",
    "    .rename({\"ts\": \"click_ts\", \"aid\": \"click_aid\", \"index\": \"click_index\"})\n",
    ")\n",
    "\n",
    "orders_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .rename({\"ts\": \"order_ts\", \"aid\": \"order_aid\", \"index\": \"order_index\"})\n",
    ")\n",
    "\n",
    "orders_after_clicks_in_sub_sessions = (\n",
    "    orders_of_sub_sessions\n",
    "    # Combine clicks and orders of sub sessions\n",
    "    .join(clicks_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only orders that happened after clicks\n",
    "    .filter(pl.col(\"click_ts\") < pl.col(\"order_ts\"))\n",
    "    .select([\"sub_session\", \"click_aid\", \"order_aid\", \"click_index\", \"order_index\"])\n",
    "    # Weight the click-to-order relation based in index. Next order has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"order_index\")-pl.col(\"click_index\"))).cast(pl.Float32))\n",
    "    .drop([\"click_index\", \"order_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each click-order pair\n",
    "click_to_order_count = (\n",
    "    orders_after_clicks_in_sub_sessions\n",
    "    .group_by([\"click_aid\", \"order_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each click\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_clicks_total_count = (\n",
    "    orders_after_clicks_in_sub_sessions\n",
    "    .group_by(\"click_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being added to order after another item has been clicked\n",
    "click_to_order_matrix = (\n",
    "    click_to_order_count\n",
    "    .join(aid_clicks_total_count, on=\"click_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"click_aid\", \"order_aid\"])\n",
    ")\n",
    "\n",
    "print(click_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", click_to_order_matrix.select(\"click_aid\").n_unique())\n",
    "print(\"Total probability:\", click_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "click_to_order_matrix.write_csv(\"./click_to_order_matrix_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cart to click matrix\n",
    "Cart to click matrix is defined as the probabilities of other aids being clicked immediately after an aid is added to cart."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get carts and clicks of sub sessions\n",
    "carts_of_sub_sessions = get_carts_of_sub_session(sub_sessions)\n",
    "\n",
    "clicks_of_sub_sessions = get_clicks_of_sub_session(sub_sessions)\n",
    "\n",
    "clicks_after_carts_in_sub_sessions = (\n",
    "    clicks_of_sub_sessions\n",
    "    # Combine carts and clicks of sub sessions\n",
    "    .join(carts_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only clicks that happened after carts\n",
    "    .filter(pl.col(\"cart_ts\") < pl.col(\"click_ts\"))\n",
    "    .select([\"sub_session\", \"cart_aid\", \"click_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same cart to click events there are\n",
    "cart_to_click_count = (\n",
    "    clicks_after_carts_in_sub_sessions\n",
    "    .group_by([\"cart_aid\", \"click_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the carts for each aid\n",
    "aid_carts_total_count = (\n",
    "    cart_to_click_count\n",
    "    .group_by(\"cart_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being clicked immediately after another item has been added to cart\n",
    "cart_to_click_matrix = (\n",
    "    cart_to_click_count\n",
    "    .join(aid_carts_total_count, on=\"cart_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"cart_aid\", \"click_aid\"])\n",
    ")\n",
    "\n",
    "print(cart_to_click_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", cart_to_click_matrix.select(\"cart_aid\").n_unique())\n",
    "print(\"Total probability:\", cart_to_click_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "cart_to_click_matrix.write_csv(\"./cart_to_click_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cart to cart matrix\n",
    "Cart to cart matrix is defined as the probabilities of other aids being added to cart later in the same sub session where an aid is added to cart."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get carts of sub sessions\n",
    "carts_of_sub_sessions = get_carts_of_sub_session(sub_sessions)\n",
    "\n",
    "next_carts_of_sub_sessions = (\n",
    "    carts_of_sub_sessions\n",
    "    .rename({\"cart_ts\": \"next_cart_ts\", \"cart_aid\": \"next_cart_aid\"})\n",
    ")\n",
    "\n",
    "# Find subsequent carts in the same sub session\n",
    "subsequent_carts = (\n",
    "    carts_of_sub_sessions\n",
    "    .join(next_carts_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    .filter(pl.col(\"cart_ts\") < pl.col(\"next_cart_ts\"))\n",
    "    .select([\"sub_session\", \"cart_aid\", \"next_cart_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same cart to cart events there are\n",
    "subsequent_carts_count = (\n",
    "    subsequent_carts\n",
    "    .group_by([\"cart_aid\", \"next_cart_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the carts for each aid\n",
    "aid_carts_total_count = (\n",
    "    subsequent_carts_count\n",
    "    .group_by(\"cart_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being added to cart after another item has been added to cart\n",
    "cart_to_cart_matrix = (\n",
    "    subsequent_carts_count\n",
    "    .join(aid_carts_total_count, on=\"cart_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"cart_aid\", \"next_cart_aid\"])\n",
    ")\n",
    "\n",
    "print(cart_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", cart_to_cart_matrix.select(\"cart_aid\").n_unique())\n",
    "print(\"Total probability:\", cart_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "cart_to_cart_matrix.write_csv(\"./cart_to_cart_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cart to cart with time decay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "carts_of_sub_sessions = (\n",
    "    get_sub_sessions(with_next_event=False)\n",
    "    .filter(pl.col(\"type\") == \"carts\")\n",
    "    .with_row_index()\n",
    "    .rename({\"ts\": \"cart_ts\", \"aid\": \"cart_aid\", \"index\": \"cart_index\"})\n",
    ")\n",
    "\n",
    "next_carts_of_sub_sessions = (\n",
    "    carts_of_sub_sessions\n",
    "    .rename({\"cart_ts\": \"next_cart_ts\", \"cart_aid\": \"next_cart_aid\", \"cart_index\": \"next_cart_index\"})\n",
    ")\n",
    "\n",
    "# Find subsequent carts in the same sub session\n",
    "subsequent_carts = (\n",
    "    carts_of_sub_sessions\n",
    "    .join(next_carts_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    .filter(pl.col(\"cart_ts\") < pl.col(\"next_cart_ts\"))\n",
    "    .select([\"sub_session\", \"cart_aid\", \"next_cart_aid\", \"cart_index\", \"next_cart_index\"])\n",
    "    # Weight the cart-to-cart relation based in index. Next cart has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"next_cart_index\")-pl.col(\"cart_index\"))).cast(pl.Float32))\n",
    "    .drop([\"cart_index\", \"next_cart_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each cart-cart pair\n",
    "cart_to_cart_count = (\n",
    "    subsequent_carts\n",
    "    .group_by([\"cart_aid\", \"next_cart_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each cart\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_carts_total_count = (\n",
    "    subsequent_carts\n",
    "    .group_by(\"cart_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being added to cart after another item has been clicked\n",
    "cart_to_cart_matrix = (\n",
    "    cart_to_cart_count\n",
    "    .join(aid_carts_total_count, on=\"cart_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"cart_aid\", \"next_cart_aid\"])\n",
    ")\n",
    "\n",
    "print(cart_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", cart_to_cart_matrix.select(\"cart_aid\").n_unique())\n",
    "print(\"Total probability:\", cart_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "cart_to_cart_matrix.write_csv(\"./cart_to_cart_matrix_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cart to order matrix\n",
    "Cart to order matrix is defined as the probabilities of other aids being ordered later in the same sub session where an aid is added to cart."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get carts and orders of sub sessions\n",
    "carts_of_sub_sessions = get_carts_of_sub_session(sub_sessions)\n",
    "\n",
    "orders_of_sub_sessions = get_orders_of_sub_session(sub_sessions)\n",
    "\n",
    "orders_after_carts_in_sub_sessions = (\n",
    "    orders_of_sub_sessions\n",
    "    # Combine carts and orders of sub sessions\n",
    "    .join(carts_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only orders that happened after carts\n",
    "    .filter(pl.col(\"cart_ts\") < pl.col(\"order_ts\"))\n",
    "    .select([\"sub_session\", \"cart_aid\", \"order_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same cart to order events there are\n",
    "cart_to_order_count = (\n",
    "    orders_after_carts_in_sub_sessions\n",
    "    .group_by([\"cart_aid\", \"order_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the carts for each aid\n",
    "aid_carts_total_count = (\n",
    "    cart_to_order_count\n",
    "    .group_by(\"cart_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being ordered after another item has been added to cart\n",
    "cart_to_order_matrix = (\n",
    "    cart_to_order_count\n",
    "    .join(aid_carts_total_count, on=\"cart_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"cart_aid\", \"order_aid\"])\n",
    ")\n",
    "\n",
    "print(cart_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", cart_to_order_matrix.select(\"cart_aid\").n_unique())\n",
    "print(\"Total probability:\", cart_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "cart_to_order_matrix.write_csv(\"./cart_to_order_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cart to order with time decay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = (\n",
    "    get_sub_sessions(with_next_event=False)\n",
    "    # Filter out clicks\n",
    "    .filter(pl.col(\"type\") != \"clicks\")\n",
    "    .with_columns(index=(pl.col(\"sub_session\") + (pl.col(\"type\") == \"orders\").cum_sum()))\n",
    ")\n",
    "\n",
    "# Get clicks and orders of sub sessions\n",
    "carts_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"carts\")\n",
    "    .rename({\"ts\": \"cart_ts\", \"aid\": \"cart_aid\", \"index\": \"cart_index\"})\n",
    ")\n",
    "\n",
    "orders_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .rename({\"ts\": \"order_ts\", \"aid\": \"order_aid\", \"index\": \"order_index\"})\n",
    ")\n",
    "\n",
    "orders_after_carts_in_sub_sessions = (\n",
    "    orders_of_sub_sessions\n",
    "    # Combine carts and orders of sub sessions\n",
    "    .join(carts_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only orders that happened after carts\n",
    "    .filter(pl.col(\"cart_ts\") < pl.col(\"order_ts\"))\n",
    "    .select([\"sub_session\", \"cart_aid\", \"order_aid\", \"cart_index\", \"order_index\"])\n",
    "    # Weight the cart-to-order relation based in index. Next order has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"order_index\")-pl.col(\"cart_index\"))).cast(pl.Float32))\n",
    "    .drop([\"cart_index\", \"order_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each cart-order pair\n",
    "cart_to_order_count = (\n",
    "    orders_after_carts_in_sub_sessions\n",
    "    .group_by([\"cart_aid\", \"order_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each cart\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_carts_total_count = (\n",
    "    orders_after_carts_in_sub_sessions\n",
    "    .group_by(\"cart_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being added to order after another item has been clicked\n",
    "cart_to_order_matrix = (\n",
    "    cart_to_order_count\n",
    "    .join(aid_carts_total_count, on=\"cart_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"cart_aid\", \"order_aid\"])\n",
    ")\n",
    "\n",
    "print(cart_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", cart_to_order_matrix.select(\"cart_aid\").n_unique())\n",
    "print(\"Total probability:\", cart_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "cart_to_order_matrix.write_csv(\"./cart_to_order_matrix_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Order to click matrix\n",
    "Order to click matrix is defined as the probabilities of other aids being clicked immediately after an aid is ordered."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get orders and clicks of sub sessions\n",
    "orders_of_sub_sessions = get_orders_of_sub_session(sub_sessions)\n",
    "\n",
    "clicks_of_sub_sessions = get_clicks_of_sub_session(sub_sessions)\n",
    "\n",
    "clicks_after_orders_in_sub_sessions = (\n",
    "    clicks_of_sub_sessions\n",
    "    # Combine orders and clicks of sub sessions\n",
    "    .join(orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only clicks that happened after orders\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"click_ts\"))\n",
    "    .select([\"sub_session\", \"order_aid\", \"click_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same order to click events there are\n",
    "order_to_click_count = (\n",
    "    clicks_after_orders_in_sub_sessions\n",
    "    .group_by([\"order_aid\", \"click_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the orders for each aid\n",
    "aid_orders_total_count = (\n",
    "    order_to_click_count\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being clicked immediately after another item has been ordered\n",
    "order_to_click_matrix = (\n",
    "    order_to_click_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"order_aid\", \"click_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_click_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_click_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_click_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_click_matrix.write_csv(\"./order_to_click_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Order to cart matrix\n",
    "Order to cart matrix is defined as the probabilities of other aids being added to cart later in the same sub session where an aid is ordered."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get orders and carts of sub sessions\n",
    "orders_of_sub_sessions = get_orders_of_sub_session(sub_sessions)\n",
    "\n",
    "carts_of_sub_sessions = get_carts_of_sub_session(sub_sessions)\n",
    "\n",
    "carts_after_orders_in_sub_sessions = (\n",
    "    carts_of_sub_sessions\n",
    "    # Combine orders and carts of sub sessions\n",
    "    .join(orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only carts that happened after orders\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"cart_ts\"))\n",
    "    .select([\"sub_session\", \"order_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same order to cart events there are\n",
    "order_to_cart_count = (\n",
    "    carts_after_orders_in_sub_sessions\n",
    "    .group_by([\"order_aid\", \"cart_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the orders for each aid\n",
    "aid_orders_total_count = (\n",
    "    order_to_cart_count\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being added to cart after another item has been ordered\n",
    "order_to_cart_matrix = (\n",
    "    order_to_cart_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"order_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_cart_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_cart_matrix.write_csv(\"./order_to_cart_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Order to cart with time decay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = (\n",
    "    get_sub_sessions(with_next_event=False)\n",
    "    # Filter out clicks\n",
    "    .filter(pl.col(\"type\") != \"clicks\")\n",
    "    .with_columns(index=(pl.col(\"sub_session\") + (pl.col(\"type\") == \"cart\").cum_sum()))\n",
    ")\n",
    "\n",
    "# Get clicks and orders of sub sessions\n",
    "orders_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .rename({\"ts\": \"order_ts\", \"aid\": \"order_aid\", \"index\": \"order_index\"})\n",
    ")\n",
    "\n",
    "carts_of_sub_sessions = (\n",
    "    sub_sessions\n",
    "    .filter(pl.col(\"type\") == \"carts\")\n",
    "    .rename({\"ts\": \"cart_ts\", \"aid\": \"cart_aid\", \"index\": \"cart_index\"})\n",
    ")\n",
    "\n",
    "carts_after_orders_in_sub_sessions = (\n",
    "    carts_of_sub_sessions\n",
    "    # Combine carts and orders of sub sessions\n",
    "    .join(orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    # Keep only orders that happened after carts\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"cart_ts\"))\n",
    "    .select([\"sub_session\", \"cart_aid\", \"order_aid\", \"cart_index\", \"order_index\"])\n",
    "    # Weight the cart-to-order relation based in index. Next order has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"cart_index\")-pl.col(\"order_index\"))).cast(pl.Float32))\n",
    "    .drop([\"cart_index\", \"order_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each order-cart pair\n",
    "order_to_cart_count = (\n",
    "    orders_after_carts_in_sub_sessions\n",
    "    .group_by([\"order_aid\", \"cart_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each cart\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_orders_total_count = (\n",
    "    orders_after_carts_in_sub_sessions\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being added to cart after another item has been ordered\n",
    "order_to_cart_matrix = (\n",
    "    order_to_cart_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"order_aid\", \"cart_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_cart_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_cart_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_cart_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_cart_matrix.write_csv(\"./order_to_cart_matrix_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Order to order matrix\n",
    "Order to order matrix is defined as the probabilities of other aids being ordered later in the same sub session where an aid is ordered."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "# Get orders of sub sessions\n",
    "orders_of_sub_sessions = get_orders_of_sub_session(sub_sessions)\n",
    "\n",
    "next_orders_of_sub_sessions = (\n",
    "    orders_of_sub_sessions\n",
    "    .rename({\"order_ts\": \"next_order_ts\", \"order_aid\": \"next_order_aid\"})\n",
    ")\n",
    "\n",
    "# Find subsequent orders in the same sub session\n",
    "subsequent_orders = (\n",
    "    orders_of_sub_sessions\n",
    "    .join(next_orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"next_order_ts\"))\n",
    "    .select([\"sub_session\", \"order_aid\", \"next_order_aid\"])\n",
    ")\n",
    "\n",
    "# Count how many same order to order events there are\n",
    "subsequent_orders_count = (\n",
    "    subsequent_orders\n",
    "    .group_by([\"order_aid\", \"next_order_aid\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Sum all the orders for each aid\n",
    "aid_orders_total_count = (\n",
    "    subsequent_orders_count\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.sum(\"count\").alias(\"total_count\"))\n",
    "    .sort(\"total_count\", descending=True)\n",
    ")\n",
    "\n",
    "# Calculate the probabilities of items being ordered after another item has been ordered\n",
    "order_to_order_matrix = (\n",
    "    subsequent_orders_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\")\n",
    "    .with_columns(\n",
    "        probability = pl.col(\"count\") / pl.col(\"total_count\")\n",
    "    )\n",
    "    .with_columns(pl.col(\"probability\").cast(pl.Float32))\n",
    "    .drop([\"count\", \"total_count\"])\n",
    "    .sort([\"order_aid\", \"next_order_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_order_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_order_matrix.write_csv(\"./order_to_order_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Order to order with time decay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "orders_of_sub_sessions = (\n",
    "    get_sub_sessions(with_next_event=False)\n",
    "    .filter(pl.col(\"type\") == \"orders\")\n",
    "    .with_row_index()\n",
    "    .rename({\"ts\": \"order_ts\", \"aid\": \"order_aid\", \"index\": \"order_index\"})\n",
    ")\n",
    "\n",
    "next_orders_of_sub_sessions = (\n",
    "    orders_of_sub_sessions\n",
    "    .rename({\"order_ts\": \"next_order_ts\", \"order_aid\": \"next_order_aid\", \"order_index\": \"next_order_index\"})\n",
    ")\n",
    "\n",
    "# Find subsequent orders in the same sub session\n",
    "subsequent_orders = (\n",
    "    orders_of_sub_sessions\n",
    "    .join(next_orders_of_sub_sessions, on=\"sub_session\", how=\"inner\")\n",
    "    .filter(pl.col(\"order_ts\") < pl.col(\"next_order_ts\"))\n",
    "    .select([\"sub_session\", \"order_aid\", \"next_order_aid\", \"order_index\", \"next_order_index\"])\n",
    "    # Weight the order-to-order relation based in index. Next order has weight 1/1, second 1/2, third 1/3, etc...\n",
    "    .with_columns(weight=(1/(pl.col(\"next_order_index\")-pl.col(\"order_index\"))).cast(pl.Float32))\n",
    "    .drop([\"order_index\", \"next_order_index\"])\n",
    ")\n",
    "\n",
    "# Sum all the weights for each order-order pair\n",
    "order_to_order_count = (\n",
    "    subsequent_orders\n",
    "    .group_by([\"order_aid\", \"next_order_aid\"])\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_count\"))\n",
    ")\n",
    "\n",
    "# Count total weight for each order\n",
    "# Since we have weights in play we need to count weighed sum instead of count of rows\n",
    "aid_orders_total_count = (\n",
    "    subsequent_orders\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.col(\"weight\").sum().alias(\"weighted_total_count\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the weighted probabilities of items being ordered after another item has been ordered\n",
    "order_to_order_matrix = (\n",
    "    order_to_order_count\n",
    "    .join(aid_orders_total_count, on=\"order_aid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        probability = (pl.col(\"weighted_count\") / pl.col(\"weighted_total_count\")).cast(pl.Float32)\n",
    "    )\n",
    "    .drop([\"weighted_count\", \"weighted_total_count\"])\n",
    "    .sort([\"order_aid\", \"next_order_aid\"])\n",
    ")\n",
    "\n",
    "print(order_to_order_matrix)\n",
    "\n",
    "# Check that probabilities sum to the amount of unique aids\n",
    "print(\"Unique aids:\", order_to_order_matrix.select(\"order_aid\").n_unique())\n",
    "print(\"Total probability:\", order_to_order_matrix.select(\"probability\").sum().select(pl.first()).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "order_to_order_matrix.write_csv(\"./order_to_order_matrix_time_decay.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Order incompatibility matrix\n",
    "Order incompatibility matrix is defined as links between items which are often ordered with same items but are never ordered together."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_sessions = get_sub_sessions(with_next_event=False)\n",
    "\n",
    "orders_of_sub_sessions_df = get_orders_of_sub_session(sub_sessions)\n",
    "\n",
    "# how many times item has to be ordered with another item so that their relation can be considered strong\n",
    "ordered_together_threshold = 4\n",
    "\n",
    "# Filter aids with too few total orders\n",
    "allowed_aids_df = (\n",
    "    orders_of_sub_sessions_df\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .filter(pl.col(\"count\") >= ordered_together_threshold)\n",
    "    .sort(\"order_aid\")\n",
    ")\n",
    "\n",
    "multi_order_sub_sessions_df = (\n",
    "    orders_of_sub_sessions_df\n",
    "    # filter aids with too few orders\n",
    "    .join(allowed_aids_df.select(\"order_aid\"), on=\"order_aid\", how=\"inner\")\n",
    "    # group orders and get unique aids for each order\n",
    "    .group_by(\"sub_session\")\n",
    "    # Remove items ordered multiple times in single session\n",
    "    .agg(pl.col(\"order_aid\").unique().sort())\n",
    "    # filter out orders with only one item left\n",
    "    .filter(pl.col(\"order_aid\").list.len() > 1)\n",
    "    .explode(\"order_aid\")\n",
    ")\n",
    "\n",
    "# Find all order aid pairs an count how many times these pairs have been ordered together\n",
    "ordered_together_count = (\n",
    "    multi_order_sub_sessions_df\n",
    "    .join(multi_order_sub_sessions_df, on=\"sub_session\", how=\"inner\")\n",
    "    .drop(\"sub_session\")\n",
    "    .group_by([\"order_aid\", \"order_aid_right\"])\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    # Filter out pairs with too few orders\n",
    "    .filter((pl.col(\"count\") >= ordered_together_threshold) & (pl.col(\"order_aid\") != pl.col(\"order_aid_right\")))\n",
    ")\n",
    "\n",
    "# Combine aid pairs into groups of aids that have been ordered together\n",
    "aids_ordered_together_df = (\n",
    "    ordered_together_count\n",
    "    .group_by(\"order_aid\")\n",
    "    .agg(pl.col(\"order_aid_right\").alias(\"ordered_together_with\"))\n",
    ")\n",
    "\n",
    "# Find all incompatible pairs by finding aids that have never been ordered together but have common aids that they are often ordered with\n",
    "incompatible_pairs = []\n",
    "\n",
    "print(\"Start\")\n",
    "for index, order_aid in enumerate(aids_ordered_together_df.select(\"order_aid\").to_numpy().reshape(-1)):\n",
    "    if (index+1) % 1000 == 0:\n",
    "        print(\"row\", index+1)\n",
    "\n",
    "    aids_ordered_together = aids_ordered_together_df.row(by_predicate=(pl.col(\"order_aid\") == order_aid))[1]\n",
    "    for aid in aids_ordered_together:\n",
    "        incompatible_aids = aids_ordered_together_df.row(by_predicate=(pl.col(\"order_aid\") == aid))[1]\n",
    "        new_incompatible_pairs = [(order_aid, aid) for aid in incompatible_aids]\n",
    "        incompatible_pairs.extend(new_incompatible_pairs)\n",
    "\n",
    "print(\"Done\")\n",
    "print()\n",
    "\n",
    "incompatible_df = (\n",
    "    pl.DataFrame(\n",
    "        data=incompatible_pairs,\n",
    "        orient='row',\n",
    "        schema={\"aid\": pl.UInt32, \"incompatible_aid\": pl.UInt32}\n",
    "    )\n",
    "    .filter(pl.col(\"aid\") != pl.col(\"incompatible_aid\"))\n",
    "    .unique()\n",
    "    .sort([\"aid\", \"incompatible_aid\"])\n",
    ")\n",
    "print(incompatible_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "incompatible_df.write_csv(\"./incompatible_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_incompatible_count = (\n",
    "    incompatible_df\n",
    "    .select(\"aid\")\n",
    "    .n_unique()\n",
    ")\n",
    "\n",
    "print(f\"Incompatible products found for {unique_incompatible_count} unique products\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Click count matrix\n",
    "Click counts of aids normalized by the maximum click count."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_855_603, 2)\n",
      "┌─────────┬──────────┐\n",
      "│ aid     ┆ weight   │\n",
      "│ ---     ┆ ---      │\n",
      "│ u32     ┆ f32      │\n",
      "╞═════════╪══════════╡\n",
      "│ 0       ┆ 0.000363 │\n",
      "│ 1       ┆ 0.000272 │\n",
      "│ 2       ┆ 0.00014  │\n",
      "│ 3       ┆ 0.019235 │\n",
      "│ 4       ┆ 0.001682 │\n",
      "│ …       ┆ …        │\n",
      "│ 1855598 ┆ 0.000058 │\n",
      "│ 1855599 ┆ 0.000107 │\n",
      "│ 1855600 ┆ 0.000676 │\n",
      "│ 1855601 ┆ 0.000701 │\n",
      "│ 1855602 ┆ 0.000157 │\n",
      "└─────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "click_count_matrix = (\n",
    "    exploded_df\n",
    "    .filter(pl.col(\"type\") == \"clicks\")\n",
    "    .group_by(\"aid\")\n",
    "    .agg(pl.len().alias(\"count\"))\n",
    "    .with_columns(weight = (pl.col(\"count\") / pl.col(\"count\").max()).cast(pl.Float32))\n",
    "    .drop(\"count\")\n",
    "    .sort(\"aid\")\n",
    ")\n",
    "\n",
    "print(click_count_matrix)\n",
    "\n",
    "click_count_matrix.write_csv(\"./click_count_matrix.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
